<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>CDC pipeline with Red Hat AMQ Streams and Red Hat Fuse</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/80fEy3uSBGQ/" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="integration" scheme="searchisko:content:tags" /><category term="jboss a-mq" scheme="searchisko:content:tags" /><category term="JBoss Fuse" scheme="searchisko:content:tags" /><category term="Red Hat AMQ" scheme="searchisko:content:tags" /><category term="Red Hat Fuse" scheme="searchisko:content:tags" /><category term="Red Hat Integration" scheme="searchisko:content:tags" /><author><name>snandaku</name></author><id>searchisko:content:id:jbossorg_blog-cdc_pipeline_with_red_hat_amq_streams_and_red_hat_fuse</id><updated>2019-09-03T07:00:44Z</updated><published>2019-09-03T07:00:44Z</published><content type="html">&lt;p&gt;Change Data Capture (CDC) is a pattern that enables database changes to be monitored and propagated to downstream systems. It is an effective way of enabling reliable microservices integration and solving typical challenges, such as gradually extracting microservices from existing monoliths.&lt;/p&gt; &lt;p&gt;With the release of &lt;a href="https://developers.redhat.com/blog/2019/07/04/announcing-red-hat-amq-streams-1-2-with-apache-kafka-2-2-support/"&gt;Red Hat AMQ Streams&lt;/a&gt; 1.2, &lt;a href="https://www.redhat.com/en/products/integration?extIdCarryOver=true&amp;#38;intcmp=701f2000001OMHaAAO&amp;#38;sc_cid=701f2000000RtqCAAS"&gt;Red Hat Integration&lt;/a&gt; now includes a developer preview of CDC features based on upstream project&lt;a href="https://debezium.io/docs/amq-streams/"&gt; Debezium&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;This article explains how to make use of Red Hat Integration to create a complete CDC pipeline. The idea is to enable applications to respond almost immediately whenever there is a data change. We capture the changes as they occur using Debezium and stream it using Red Hat AMQ Streams. We then filter and transform the data using &lt;a href="https://developers.redhat.com/products/fuse/overview"&gt;Red Hat Fuse&lt;/a&gt; and send it to Elasticsearch, where the data can be further analyzed or used by downstream systems.&lt;br /&gt; &lt;img class=" alignnone wp-image-620237 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/08/final_cdc-1024x415.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/08/final_cdc-300x122.png" alt="" width="602" height="245" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/08/final_cdc-300x122.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/08/final_cdc-768x312.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/08/final_cdc-1024x415.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/08/final_cdc.png 1600w" sizes="(max-width: 602px) 100vw, 602px" /&gt;&lt;br /&gt; &lt;span id="more-617417"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Overview of the architecture&lt;/h2&gt; &lt;p&gt;In this example, as transaction data comes in from our shopping website, it is persisted to a transaction database (MySQL DB), Debezium then captures the data changes and sends it over to the AMQ Streams topic with the table name (in our case transaction). We then read the &lt;a href="https://www.redhat.com/en/topics/integration/what-is-apache-kafka?extIdCarryOver=true&amp;#38;intcmp=701f2000001OMHaAAO&amp;#38;sc_cid=701f2000000RtqCAAS"&gt;Apache Kafka&lt;/a&gt; topic using Red Hat Fuse and filter large transactions (transactions &amp;#62; 1000) and send it to Elasticsearch where the data can be used/analyzed by downstream systems. Fuse Online is an integration Platform-as-a-Service (iPaaS) solution that makes it easy for business users to collaborate with integration experts and application developers.&lt;/p&gt; &lt;h2&gt;Preparing the demo environment&lt;/h2&gt; &lt;p&gt;Let&amp;#8217;s install the necessary components for this demonstration on &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt;, which enables efficient container orchestration, allowing rapid container provisioning, deploying, scaling, and management. Red Hat Integration on OpenShift helps us rapidly create and manage the web-scale cloud-native applications with ease.&lt;/p&gt; &lt;p&gt;The OpenShift Container Platform CLI exposes commands for managing your applications, as well as lower-level tools to interact with each component of your system. We will be making use of the OC tool to create/deploy projects and applications. First, we will create a new project and provision a MySQL DB.&lt;/p&gt; &lt;pre&gt;$oc new-project debezium-cdc $oc new-app --name=mysql debezium/example-mysql:0.9                          -e MYSQL_ROOT_PASSWORD=password                          -e MYSQL_USER=testUser                          -e MYSQL_PASSWORD=password                          -e MYSQL_DATABASE=sampledb &lt;/pre&gt; &lt;p&gt;We will also create a transaction database for the shopping website.&lt;/p&gt; &lt;pre&gt;$oc get pods $oc rsh &amp;#60;pod_name&amp;#62; $mysql -u root -ppassword -h mysql sampledb mysql&amp;#62; CREATE TABLE transaction (transaction_id serial PRIMARY KEY,userId integer NOT NULL, amount integer NOT NULL,last_login TIMESTAMP); &lt;/pre&gt; &lt;p&gt;Follow the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_amq/7.3/html/using_amq_streams_on_openshift_container_platform/getting-started-str#downloads-str"&gt;Red Hat AMQ Streams documentation&lt;/a&gt; to provision Red Hat AMQ Streams using the AMQ Streams Operator. Next, we will deploy the&lt;a href="https://access.redhat.com/documentation/en-us/red_hat_amq/7.3/html/using_amq_streams_on_openshift_container_platform/getting-started-str#using-kafka-connect-with-plug-ins-str"&gt; Kafka Connect s2i&lt;/a&gt;. Next, download the necessary driver for MySQL along with the Debezium MySQL connector from the&lt;a href="https://debezium.io/docs/amq-streams/"&gt; Debezium website&lt;/a&gt;. Make sure to copy the driver into the connector folder.&lt;/p&gt; &lt;p&gt;Now, we can configure the Kafka connect utility with the MySQL Debezium connector that we have downloaded.&lt;/p&gt; &lt;pre&gt;$oc get buildconfigs $oc start-build &amp;#60;build-config-name&amp;#62; --from-dir=&amp;#60;connector_dir&amp;#62; &lt;/pre&gt; &lt;p&gt;We will now use a POST command to configure the Debezium connector with our MySQL DB configuration.&lt;/p&gt; &lt;pre&gt;PUT &amp;#60;kafka-connect-pod-route-url&amp;#62;&lt;a href="http://my-connect-cluster-connect-api-dbz-mysql.apps.florida-4a69.openshiftworkshop.com/connectors/debezium-connector-mysql/config"&gt;/connectors/debezium-connector-mysql/config&lt;/a&gt; {     "connector.class": "io.debezium.connector.mysql.MySqlConnector",     "tasks.max": "1",     "database.hostname": "mysql", → &lt;b&gt;&lt;i&gt;Database host name&lt;/i&gt;&lt;/b&gt;      "database.port": "3306", → &lt;b&gt;&lt;i&gt;Port&lt;/i&gt;&lt;/b&gt;     "database.user": "root", → &lt;b&gt;&lt;i&gt;Username&lt;/i&gt;&lt;/b&gt;     "database.password": "password", → &lt;b&gt;&lt;i&gt;Password&lt;/i&gt;&lt;/b&gt;     "database.server.id": "184054",     "database.server.name": "sampledb", → &lt;b&gt;&lt;i&gt;Database name&lt;/i&gt;&lt;/b&gt;     "database.whitelist": "sampledb",     "database.history.kafka.bootstrap.servers": "my-cluster-kafka-bootstrap.svc:9092", → &lt;b&gt;&lt;i&gt;Kafka cluster url&lt;/i&gt;&lt;/b&gt;     "database.history.kafka.topic": "changes-topic",     "decimal.handling.mode" : "double",     "transforms": "route",     "transforms.route.type": "org.apache.kafka.connect.transforms.RegexRouter",     "transforms.route.regex": "([^.]+)\\.([^.]+)\\.([^.]+)",     "transforms.route.replacement": "$3" } &lt;/pre&gt; &lt;p&gt;Next, we&amp;#8217;ll spin up Red Hat Fuse Online. &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_fuse/7.3/html/integrating_applications_with_fuse_online/fuse-online-on-ocp_ug"&gt;&lt;span style="font-weight: 400;"&gt;Follow the documentation&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt; to install Fuse Online on the OpenShift instance. &lt;/span&gt;&lt;span style="font-weight: 400;"&gt;Once the connectors are set up, we can create the integration. &lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;Integration is a four-step process, where data is read from the Kafka topic, schema are mapped, filtered, and written on to an Elasticsearch end point.&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;img class=" alignnone wp-image-617627 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/08/fuse_online_integ-1024x477.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/08/fuse_online_integ-300x140.png" alt="" width="632" height="295" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/08/fuse_online_integ-300x140.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/08/fuse_online_integ-768x358.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/08/fuse_online_integ-1024x477.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/08/fuse_online_integ.png 1600w" sizes="(max-width: 632px) 100vw, 632px" /&gt;&lt;/p&gt; &lt;p&gt;We will now need an Elasticsearch instance, which can be publicly hosted/ installed on OC. Create an index called transaction, and we&amp;#8217;ll push to this index from our Fuse Online Integration.&lt;/p&gt; &lt;p&gt;Finally, let&amp;#8217;s deploy an e-shopping web application. For this, we will be using &lt;a href="https://developers.redhat.com/blog/2019/03/07/quarkus-next-generation-kubernetes-native-java-framework/"&gt;Quarkus&lt;/a&gt; (supersonic, subatomic Java) to spin up a simple CRUD UI. Quarkus provides an effective solution for running Java in this new world of serverless, microservices, containers, Kubernetes, FaaS, and the cloud because it has been designed with these technologies in mind.&lt;/p&gt; &lt;pre&gt;oc new-app quay.io/quarkus/ubi-quarkus-native-s2i:19.0.2~https://github.com/snandakumar87/quarkus-transaction-crud oc cancel-build bc/quarkus-transaction-crud oc patch bc/quarkus-transaction-crud -p '{"spec":{"resources":{"limits":{"cpu":"5", "memory":"6Gi"}}}}' oc start-build bc/quarkus-transaction-crud oc expose svc/quarkus-transaction-crud&lt;/pre&gt; &lt;h2&gt;CDC in action&lt;/h2&gt; &lt;p&gt;&lt;iframe class='youtube-player' type='text/html' width='640' height='360' src='https://www.youtube.com/embed/uox8l1GtPSQ?version=3&amp;#038;rel=1&amp;#038;fs=1&amp;#038;autohide=2&amp;#038;showsearch=0&amp;#038;showinfo=1&amp;#038;iv_load_policy=1&amp;#038;wmode=transparent' allowfullscreen='true' style='border:0;'&gt;&lt;/iframe&gt;&lt;/p&gt; &lt;p&gt;Open up the Red Hat OpenShift console and go into the project (debezium-cdc). You should see Multiple Application pods listed. Look for the “quarkus-transaction-crud” pod and follow the external route to land on the e-shopping web page.&lt;/p&gt; &lt;p&gt;&lt;img class=" alignnone wp-image-617647 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/08/crud_ui-1024x248.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/08/crud_ui-300x73.png" alt="" width="658" height="160" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/08/crud_ui-300x73.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/08/crud_ui-768x186.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/08/crud_ui-1024x248.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/08/crud_ui.png 1600w" sizes="(max-width: 658px) 100vw, 658px" /&gt;&lt;/p&gt; &lt;p&gt;Click on buy for the Macbook Pro, then navigate back to the OpenShift console, and look for an application pod “mysql” and navigate to the terminal. We will now verify the transaction data in the MySQL database.&lt;/p&gt; &lt;pre&gt;oc rsh &amp;#60;pod_name&amp;#62;) mysql -u &amp;#60;username&amp;#62; -p&amp;#60;password&amp;#62; -h mysql &amp;#60;databasename&amp;#62; Select * from transaction;&lt;/pre&gt; &lt;p&gt;&lt;img class=" alignnone wp-image-617657 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/08/txn_DB-1024x442.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/08/txn_DB-300x130.png" alt="" width="667" height="289" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/08/txn_DB-300x130.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/08/txn_DB-768x332.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/08/txn_DB-1024x442.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/08/txn_DB.png 1600w" sizes="(max-width: 667px) 100vw, 667px" /&gt;&lt;/p&gt; &lt;p&gt;Now that the data is entered into the DB, we can quickly look at the Change Data Capture. Open up the logs for the Kafka-Connect pod.&lt;/p&gt; &lt;p&gt;&lt;img class=" alignnone wp-image-617667 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/08/CDC_logs-1024x487.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/08/CDC_logs-300x143.png" alt="" width="669" height="319" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/08/CDC_logs-300x143.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/08/CDC_logs-768x365.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/08/CDC_logs-1024x487.png 1024w" sizes="(max-width: 669px) 100vw, 669px" /&gt;&lt;/p&gt; &lt;p&gt;The change is captured and added to our Kafka topic. Now let&amp;#8217;s switch to the Red Hat Fuse online console.&lt;/p&gt; &lt;p&gt;&lt;img class=" alignnone wp-image-617677 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/08/fuse_online-1024x294.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/08/fuse_online-300x86.png" alt="" width="663" height="190" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/08/fuse_online-300x86.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/08/fuse_online-768x221.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/08/fuse_online-1024x294.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/08/fuse_online.png 1600w" sizes="(max-width: 663px) 100vw, 663px" /&gt;&lt;/p&gt; &lt;p&gt;We can see that the transaction has been read from the Kafka topic, filtered, and sent to Elasticsearch. Let&amp;#8217;s do a simple GET on the elastic search REST endpoint to look for the new records that have been read from the Kafka topic.&lt;/p&gt; &lt;pre&gt;GET &amp;#60;elastic-url&amp;#62;/transaction/_search&lt;/pre&gt; &lt;p&gt;&lt;img class=" alignnone wp-image-617707 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/08/elastic_post-1024x457.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/08/elastic_post-300x134.png" alt="" width="660" height="295" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/08/elastic_post-300x134.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/08/elastic_post-768x342.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/08/elastic_post-1024x457.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/08/elastic_post.png 1292w" sizes="(max-width: 660px) 100vw, 660px" /&gt;&lt;/p&gt; &lt;h2&gt;Summary&lt;/h2&gt; &lt;p&gt;By harnessing the power of CDC features using Debezium, we can capture the data changes as they happen, which can now be streamed so that the downstream systems can make use of it. Red Hat Fuse unlocks the potential to&lt;a href="https://developers.redhat.com/products/fuse/connectors"&gt; connect several of these external systems&lt;/a&gt;, thereby completing the data pipeline.&lt;/p&gt; &lt;h3&gt;References&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://www.redhat.com/en/products/integration?extIdCarryOver=true&amp;#38;sc_cid=701f20000012i69AAA"&gt;Red Hat Integration&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/products/fuse/overview"&gt;Red Hat Fuse&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://debezium.io/docs/amq-streams/"&gt;Debezium&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://quarkus.io/"&gt;Quarkus&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F09%2F03%2Fcdc-pipeline-with-red-hat-amq-streams-and-red-hat-fuse%2F&amp;#38;linkname=CDC%20pipeline%20with%20Red%20Hat%20AMQ%20Streams%20and%20Red%20Hat%20Fuse" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F09%2F03%2Fcdc-pipeline-with-red-hat-amq-streams-and-red-hat-fuse%2F&amp;#38;linkname=CDC%20pipeline%20with%20Red%20Hat%20AMQ%20Streams%20and%20Red%20Hat%20Fuse" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F09%2F03%2Fcdc-pipeline-with-red-hat-amq-streams-and-red-hat-fuse%2F&amp;#38;linkname=CDC%20pipeline%20with%20Red%20Hat%20AMQ%20Streams%20and%20Red%20Hat%20Fuse" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F09%2F03%2Fcdc-pipeline-with-red-hat-amq-streams-and-red-hat-fuse%2F&amp;#38;linkname=CDC%20pipeline%20with%20Red%20Hat%20AMQ%20Streams%20and%20Red%20Hat%20Fuse" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F09%2F03%2Fcdc-pipeline-with-red-hat-amq-streams-and-red-hat-fuse%2F&amp;#38;linkname=CDC%20pipeline%20with%20Red%20Hat%20AMQ%20Streams%20and%20Red%20Hat%20Fuse" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F09%2F03%2Fcdc-pipeline-with-red-hat-amq-streams-and-red-hat-fuse%2F&amp;#38;linkname=CDC%20pipeline%20with%20Red%20Hat%20AMQ%20Streams%20and%20Red%20Hat%20Fuse" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F09%2F03%2Fcdc-pipeline-with-red-hat-amq-streams-and-red-hat-fuse%2F&amp;#38;linkname=CDC%20pipeline%20with%20Red%20Hat%20AMQ%20Streams%20and%20Red%20Hat%20Fuse" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F09%2F03%2Fcdc-pipeline-with-red-hat-amq-streams-and-red-hat-fuse%2F&amp;#038;title=CDC%20pipeline%20with%20Red%20Hat%20AMQ%20Streams%20and%20Red%20Hat%20Fuse" data-a2a-url="https://developers.redhat.com/blog/2019/09/03/cdc-pipeline-with-red-hat-amq-streams-and-red-hat-fuse/" data-a2a-title="CDC pipeline with Red Hat AMQ Streams and Red Hat Fuse"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/09/03/cdc-pipeline-with-red-hat-amq-streams-and-red-hat-fuse/"&gt;CDC pipeline with Red Hat AMQ Streams and Red Hat Fuse&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/80fEy3uSBGQ" height="1" width="1" alt=""/&gt;</content><summary>Change Data Capture (CDC) is a pattern that enables database changes to be monitored and propagated to downstream systems. It is an effective way of enabling reliable microservices integration and solving typical challenges, such as gradually extracting microservices from existing monoliths. With the release of Red Hat AMQ Streams 1.2, Red Hat Integration now includes a developer preview of CDC fe...</summary><dc:creator>snandaku</dc:creator><dc:date>2019-09-03T07:00:44Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/09/03/cdc-pipeline-with-red-hat-amq-streams-and-red-hat-fuse/</feedburner:origLink></entry><entry><title>Report from July 2019 ISO C++ Meeting (Core Language)</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/aJn60tEg8yM/" /><category term="C++" scheme="searchisko:content:tags" /><category term="Developer Tools" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="language" scheme="searchisko:content:tags" /><category term="Programming Languages" scheme="searchisko:content:tags" /><category term="Red Hat Developer Toolset" scheme="searchisko:content:tags" /><author><name>Jason Merrill</name></author><id>searchisko:content:id:jbossorg_blog-report_from_july_2019_iso_c_meeting_core_language</id><updated>2019-09-03T07:00:41Z</updated><published>2019-09-03T07:00:41Z</published><content type="html">&lt;p&gt;The summer 2019 &lt;a href="https://isocpp.org/std/meetings-and-participation/upcoming-meetings"&gt;C++ meeting&lt;/a&gt; was in Cologne, Germany, 10 years since our last meeting in Germany. As usual, Red Hat sent three of us to the meeting: I attended in the Core language &lt;a href="https://isocpp.org/std/the-committee"&gt;working group&lt;/a&gt; (CWG), Jonathan Wakely in Library (LWG), and Thomas Rodgers in SG1 (parallelism and concurrency).&lt;/p&gt; &lt;p&gt;At the end of the meeting, as planned, we voted to send out a draft of the C++20 standard for comments from the national bodies. The most surprising thing about it was the proposal to:&lt;/p&gt; &lt;h4&gt;&lt;a href="http://wg21.link/p1823r0"&gt;Remove Contracts from C++20&lt;/a&gt;&lt;/h4&gt; &lt;p&gt;The disagreements from the &lt;a href="https://developers.redhat.com/blog/2019/04/11/report-from-the-february-2019-iso-c-meeting-core-language-working-group/"&gt;February meeting in Kona&lt;/a&gt; continued at this meeting; since no consensus seemed likely during the week, the two sides agreed to remove the Contracts feature from C++20 and revisit it for the next standard.  A new Study Group was formed for continuing discussion, to be led by a neutral party.&lt;/p&gt; &lt;p&gt;Other than that, the contents of the draft were about as expected. Quite a few minor features and corrections that had previously been approved by Evolution made it through Core and into the draft at this meeting:&lt;/p&gt; &lt;h3&gt;Concepts&lt;/h3&gt; &lt;h4&gt;&lt;a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p0848r3.html"&gt;Conditionally trivial special member functions&lt;/a&gt;&lt;/h4&gt; &lt;p&gt;This clarifies the semantics of overloaded of constructors and destructors with different constraints, for example:&lt;/p&gt; &lt;pre class="moz-text-flowed"&gt;struct empty {}; template &amp;#60;typename T&amp;#62; class optional { bool engaged = false; union {     empty _ = {};     T value;   }; public:   constexpr optional() = default; // non-trivial due to default member initializer   constexpr optional(optional const&amp;#38;) requires std::is_trivially_copy_constructible_v&amp;#60;T&amp;#62; = default;   constexpr optional(optional const&amp;#38; o): engaged(o.engaged) { if (o.engaged) new (&amp;#38;value) T(o.value); }   ~optional() requires std::is_trivially_destructible_v&amp;#60;T&amp;#62; = default;   ~optional() { if (engaged) value.~T(); }   // ... };&lt;/pre&gt; &lt;p&gt;If the requirements of the first overload of the copy constructor or destructor are satisfied, it effectively hides the second overload which is less constrained, so &lt;tt&gt;optional&amp;#60;int&amp;#62;&lt;/tt&gt; is trivially copy-constructible and trivially destructible.&lt;/p&gt; &lt;h4&gt;&lt;a href="http://wg21.link/p1616r1"&gt;Unconstrained template template parameters and constrained templates&lt;/a&gt;&lt;/h4&gt; &lt;p&gt;Normally, a template template parameter (TTP) must be at least as specialized as its template template argument. However, that meant that there was no way to write a TTP that accepted any template regardless of its constraints:&lt;/p&gt; &lt;pre class="moz-text-flowed"&gt;template &amp;#60;template &amp;#60;typename&amp;#62; typename TT&amp;#62; struct A {}; template &amp;#60;typename T&amp;#62; concept Any = true; template &amp;#60;Any&amp;#62; struct B; A&amp;#60;B&amp;#62; a; // previously error (TT is less constrained than B), now OK&lt;/pre&gt; &lt;p&gt;As I pointed out during discussion of this paper, there is already an exception for a TTP with a template parameter pack accepting an argument template with a specific number of template parameters; this adds the parallel escape hatch for constraints, so that a TTP with no constraints at all will match a constrained argument template.&lt;/p&gt; &lt;h4 class="moz-text-flowed"&gt;&lt;a href="http://wg21.link/p1452r2"&gt;Removing return-type requirements&lt;/a&gt;&lt;/h4&gt; &lt;p&gt;For a compound-requirement in a requires-expression, it was found unclear whether&lt;/p&gt; &lt;pre class="moz-text-flowed"&gt;  { expr } -&amp;#62; Type&lt;/pre&gt; &lt;div class="moz-text-flowed" lang="x-unicode"&gt;ought to require the exact type or convertibility. So, use of a type here was removed for C++20, and users can choose for themselves with&lt;/div&gt; &lt;pre class="moz-text-flowed"&gt;  { expr } -&amp;#62; Same&amp;#60;Type&amp;#62;&lt;/pre&gt; &lt;div class="moz-text-flowed" lang="x-unicode"&gt;or&lt;/div&gt; &lt;pre class="moz-text-flowed"&gt;  { expr } -&amp;#62; ConvertibleTo&amp;#60;Type&amp;#62;&lt;/pre&gt; &lt;h3 class="moz-text-flowed"&gt;Modules&lt;/h3&gt; &lt;h4 class="moz-text-flowed"&gt;&lt;a href="http://wg21.link/p1766r1"&gt;Mitigating minor modules maladies&lt;/a&gt;&lt;/h4&gt; &lt;p&gt;First, structs with only typedef names for linkage purposes, for example:&lt;/p&gt; &lt;pre class="moz-text-flowed"&gt;typedef struct { int i; } foobar;&lt;/pre&gt; &lt;p&gt;have always been fragile if any of their members are affected by that linkage, e.g. member functions or static data members, and we finally made such members ill-formed. Because this is a C compatibility hack, limiting it to definitions that can actually appear in C seems reasonable.&lt;/p&gt; &lt;p&gt;Second, it is now ill-formed (no diagnostic required) for a function to have different default arguments in different translation units.&lt;/p&gt; &lt;h4&gt;&lt;a href="http://wg21.link/p1811r0"&gt;Relaxing re-export redefinition restrictions&lt;/a&gt;&lt;/h4&gt; &lt;p&gt;Allows a single definition of an entity in a translation unit even if a definition is also available from an imported module, to reduce headaches from multiple inclusion of legacy header files.&lt;/p&gt; &lt;h4&gt;&lt;a href="http://wg21.link/p1703r1"&gt;Recognizing header units&lt;/a&gt;&lt;/h4&gt; &lt;p&gt;Requires that a header unit import declaration be on a line by itself, starting with &lt;tt&gt;import&lt;/tt&gt; or &lt;tt&gt;export import&lt;/tt&gt;, for easier partial preprocessing.&lt;/p&gt; &lt;h3&gt;Spaceship (operator&amp;#60;=&amp;#62;)&lt;/h3&gt; &lt;h4&gt;&lt;a href="http://wg21.link/p1186r3"&gt;When do you actually use operator&amp;#60;=&amp;#62;?&lt;/a&gt;&lt;/h4&gt; &lt;p&gt;Allows synthesis of &lt;tt&gt;operator&amp;#60;=&amp;#62;&lt;/tt&gt; from &lt;tt&gt;operator&amp;#60;&lt;/tt&gt; and &lt;tt&gt;operator==&lt;/tt&gt; if an explicit return type is provided.&lt;/p&gt; &lt;h4&gt;&lt;a href="http://wg21.link/p1630r1"&gt;Spaceship needs a tune-up&lt;/a&gt;&lt;/h4&gt; &lt;p&gt;Clarification of comparison operator synthesis and how rewritten comparison operators participate in overload resolution.&lt;/p&gt; &lt;h3&gt;constexpr&lt;/h3&gt; &lt;h4&gt;&lt;a href="http://wg21.link/p1331r2"&gt;Trivial default initialization in constexpr&lt;/a&gt;&lt;/h4&gt; &lt;p&gt;In C++17, a variable in a constexpr function must be initialized.  This paper removes that requirement and replaces it with a requirement that an object must be given a value before it is read from. So,&lt;/p&gt; &lt;pre class="moz-text-flowed"&gt;constexpr int f(int i) {   int j; // error in C++17, OK in C++20   j = i; // j now has a value   return j; // OK } constexpr int x = f(42); // OK constexpr int g(int i) {   int j; // error in C++17, OK in C++20   return j; // ill-formed, no diagnostic required: will never produce a constant value } constexpr int y = g(42); // error, non-constant initializer&lt;/pre&gt; &lt;h4&gt;&lt;a href="http://wg21.link/p1668r1"&gt;Unevaluated asm in constexpr functions&lt;/a&gt;&lt;/h4&gt; &lt;p&gt;Another thing that&amp;#8217;s no longer prohibited in a constexpr function; it just doesn&amp;#8217;t produce a constant value.&lt;/p&gt; &lt;h4&gt;&lt;a href="http://wg21.link/p1143r2"&gt;Adding the constinit keyword&lt;/a&gt;&lt;/h4&gt; &lt;p&gt;A new keyword to require constant (static) initialization of a non-const variable:&lt;/p&gt; &lt;pre class="moz-text-flowed"&gt;constexpr int f(int x) { return x; } constinit int i = f(42); // OK constinit int j = f(i);  // error, i isn't constant&lt;/pre&gt; &lt;h4&gt;&lt;a href="http://wg21.link/p0784r7"&gt;More constexpr containers&lt;/a&gt;&lt;/h4&gt; &lt;p&gt;Allowing containers such as &lt;tt&gt;std::vector&lt;/tt&gt; to be used in constexpr functions, by requiring that allocation/deallocation pairs be omitted during constant evaluation (as has been permitted in dynamically evaluated code since C++14).&lt;/p&gt; &lt;h4&gt;&lt;a href="http://wg21.link/p1301r4"&gt;[[nodiscard(&amp;#8220;should have a reason&amp;#8221;)]]&lt;/a&gt;&lt;/h4&gt; &lt;h4&gt;&lt;a href="http://wg21.link/p1771r1"&gt;[[nodiscard]] for constructors&lt;/a&gt;&lt;/h4&gt; &lt;p&gt;Filling in missing functionality for &lt;tt&gt;[[nodiscard]]&lt;/tt&gt;.&lt;/p&gt; &lt;h4&gt;&lt;a href="http://wg21.link/p1816r0"&gt;Class template argument deduction (CTAD) for aggregates&lt;/a&gt;&lt;/h4&gt; &lt;h4&gt;&lt;a href="http://wg21.link/p1814r0"&gt;CTAD for alias templates&lt;/a&gt;&lt;/h4&gt; &lt;p&gt;Supporting CTAD for additional templates. There was also a proposal to support deduction from inherited constructors, but the wording wasn&amp;#8217;t ready in time.&lt;/p&gt; &lt;h4 class="moz-text-flowed"&gt;&lt;a href="http://wg21.link/p1099r5"&gt;Using enum&lt;/a&gt;&lt;/h4&gt; &lt;p&gt;Allowing a user to import the enumerators of a scoped enumeration into the current scope, so they can be named without explicit scope.&lt;/p&gt; &lt;pre class="moz-text-flowed"&gt;  enum class A { a1 };   using enum A;   int i = a1;&lt;/pre&gt; &lt;p&gt;Note that there is significant &lt;a href="https://en.wiktionary.org/wiki/bikeshedding"&gt;bikeshedding&lt;/a&gt; happening on the lists at the moment, so the syntax may change before the final C++20 standard.&lt;/p&gt; &lt;h4&gt;&lt;a href="http://wg21.link/p0388r4"&gt;Conversion to arrays of unknown bound&lt;/a&gt;&lt;/h4&gt; &lt;p&gt;Permitting conversion from array of known bound to array of unknown bound in pointer conversion and reference binding.&lt;/p&gt; &lt;pre class="moz-text-flowed"&gt; int arr[42]; void f(int(&amp;#38;)[]);   void g(int(*)[]);   f(arr);    // now OK   g(&amp;#38;arr);   // now OK&lt;/pre&gt; &lt;h4&gt;&lt;a href="http://wg21.link/p1825r0"&gt;More implicit moves&lt;/a&gt;&lt;/h4&gt; &lt;p&gt;Loosens the C++11 conditions for implicit move in throw or return in various ways: now rvalue references will also be implicitly moved from, and implicit move is not limited to a constructor taking an rvalue reference to the returned expression&amp;#8217;s type.&lt;/p&gt; &lt;pre class="moz-text-flowed"&gt;  struct Movable { Movable(Movable&amp;#38;&amp;#38;); };   Movable f1(Movable &amp;#38;&amp;#38;r) { return r; } // now moves   struct Derived: Movable { };   Movable f2(Derived d) { return d; }   // now moves   struct Proxy { Proxy(Movable); };   Proxy f3(Movable m) { return m; }     // now moves&lt;/pre&gt; &lt;h4&gt;&lt;a href="http://wg21.link/p1152r4"&gt;Deprecating some uses of volatile&lt;/a&gt;&lt;/h4&gt; &lt;p&gt;Expressions such as ++ or += that involve both load and store of a volatile lvalue are deprecated, as are volatile-qualified parameter and return types.&lt;/p&gt; &lt;h4&gt;&lt;a href="http://wg21.link/p1161r3"&gt;Deprecating comma in subscripting expressions&lt;/a&gt;&lt;/h4&gt; &lt;p&gt;The authors would like to be able to use the comma in an array subscript to separate multiple arguments to &lt;tt&gt;operator[]&lt;/tt&gt; rather than as the comma operator, so the existing semantics are deprecated in C++20 to make room for new semantics in a future standard.&lt;/p&gt; &lt;pre class="moz-text-flowed"&gt;  array[x,y]    // Deprecated, uses y as index/key&lt;/pre&gt; &lt;h4&gt;&lt;a href="http://wg21.link/p0735r1"&gt;Interaction of memory_order_consume with release sequences&lt;/a&gt;&lt;/h4&gt; &lt;p&gt;A fairly subtle adjustment to consume semantics to make them less broken on ARM.  Most implementations treat consume as acquire, so this will not affect users.&lt;/p&gt; &lt;p&gt;The &lt;a href="https://isocpp.org/std/meetings-and-participation/upcoming-meetings"&gt;next meeting&lt;/a&gt; will be in Belfast, Northern Ireland in November, where we will start to process national body comments on the C++20 draft.  If you have any comments, please send them to a committee member to pass along.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F09%2F03%2Freport-from-july-2019-iso-c-meeting-core-language%2F&amp;#38;linkname=Report%20from%20July%202019%20ISO%20C%2B%2B%20Meeting%20%28Core%20Language%29" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F09%2F03%2Freport-from-july-2019-iso-c-meeting-core-language%2F&amp;#38;linkname=Report%20from%20July%202019%20ISO%20C%2B%2B%20Meeting%20%28Core%20Language%29" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F09%2F03%2Freport-from-july-2019-iso-c-meeting-core-language%2F&amp;#38;linkname=Report%20from%20July%202019%20ISO%20C%2B%2B%20Meeting%20%28Core%20Language%29" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F09%2F03%2Freport-from-july-2019-iso-c-meeting-core-language%2F&amp;#38;linkname=Report%20from%20July%202019%20ISO%20C%2B%2B%20Meeting%20%28Core%20Language%29" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F09%2F03%2Freport-from-july-2019-iso-c-meeting-core-language%2F&amp;#38;linkname=Report%20from%20July%202019%20ISO%20C%2B%2B%20Meeting%20%28Core%20Language%29" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F09%2F03%2Freport-from-july-2019-iso-c-meeting-core-language%2F&amp;#38;linkname=Report%20from%20July%202019%20ISO%20C%2B%2B%20Meeting%20%28Core%20Language%29" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F09%2F03%2Freport-from-july-2019-iso-c-meeting-core-language%2F&amp;#38;linkname=Report%20from%20July%202019%20ISO%20C%2B%2B%20Meeting%20%28Core%20Language%29" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F09%2F03%2Freport-from-july-2019-iso-c-meeting-core-language%2F&amp;#038;title=Report%20from%20July%202019%20ISO%20C%2B%2B%20Meeting%20%28Core%20Language%29" data-a2a-url="https://developers.redhat.com/blog/2019/09/03/report-from-july-2019-iso-c-meeting-core-language/" data-a2a-title="Report from July 2019 ISO C++ Meeting (Core Language)"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/09/03/report-from-july-2019-iso-c-meeting-core-language/"&gt;Report from July 2019 ISO C++ Meeting (Core Language)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/aJn60tEg8yM" height="1" width="1" alt=""/&gt;</content><summary>The summer 2019 C++ meeting was in Cologne, Germany, 10 years since our last meeting in Germany. As usual, Red Hat sent three of us to the meeting: I attended in the Core language working group (CWG), Jonathan Wakely in Library (LWG), and Thomas Rodgers in SG1 (parallelism and concurrency). At the end of the meeting, as planned, we voted to send out a draft of the C++20 standard for comments from ...</summary><dc:creator>Jason Merrill</dc:creator><dc:date>2019-09-03T07:00:41Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/09/03/report-from-july-2019-iso-c-meeting-core-language/</feedburner:origLink></entry><entry><title>What's Coming To Keycloak</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/XDWUfmSnn4Y/2019-roadmap.html" /><category term="feed_group_name_keycloak" scheme="searchisko:content:tags" /><category term="feed_name_keycloak" scheme="searchisko:content:tags" /><author><name>Stian Thorgersen</name></author><id>searchisko:content:id:jbossorg_blog-what_s_coming_to_keycloak</id><updated>2019-09-03T00:00:00Z</updated><published>2019-09-03T00:00:00Z</published><content type="html">&lt;h3&gt;New Account Console and Account REST API&lt;/h3&gt; &lt;p&gt;The current account console is getting dated. It is also having issues around usability and being hard to extend. For this reason we had the UXD team at Red Hat develop &lt;a href="https://marvelapp.com/c90dfi0/screen/59941600"&gt;wireframes&lt;/a&gt; for a new account console. The new console is being implemented with React.js providing a better user experience as well as making it easier to extend and customise.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://issues.jboss.org/browse/KEYCLOAK-6197"&gt;JIRA - Account Console&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://issues.jboss.org/browse/KEYCLOAK-7428"&gt;JIRA - Account REST API&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;WebAuthn&lt;/h3&gt; &lt;p&gt;We are working towards adding WebAuthn support both for two factor authentication and passwordless experience. This task is not as simple as adding an authenticator for WebAuth, but will also require work on improving authentication flows and the account console.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://github.com/keycloak/keycloak-community/blob/master/design/multi-factor-admin-and-step-up.md"&gt;Design proposal - Authentication flow improvements&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/keycloak/keycloak-community/blob/master/design/web-authn-authenticator.md"&gt;Design proposal - WebAuthn Authenticator&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/keycloak/keycloak-community/blob/master/design/web-authn-two-factor.md"&gt;Design proposal - WebAuthn Two factor&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://issues.jboss.org/browse/KEYCLOAK-7159"&gt;JIRA - Two factor&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://issues.jboss.org/browse/KEYCLOAK-9365"&gt;JIRA - Passwordless&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;Operator&lt;/h3&gt; &lt;p&gt;Operators are becoming an important way to manage software running on Kubernetes and we are working on an operator for Keycloak. The aim is to have an operator published on &lt;a href="https://operatorhub.io/"&gt;OperatorHub.io&lt;/a&gt; soon which provides basic install and seamless upgrade capabilities. This will be based on the awesome work done by the Red Hat Integreatly team.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://issues.jboss.org/browse/KEYCLOAK-7300"&gt;JIRA&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/integr8ly/keycloak-operator"&gt;Integreatly Keycloak Operator&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;Vault&lt;/h3&gt; &lt;p&gt;At the moment to keep credentials such as LDAP bind credentials more secure it is required to encrypt the whole database. This can be complex and can also have a performance overhead.&lt;/p&gt; &lt;p&gt;We are working towards enabling loading credentials, such as LDAP bind credential and SMTP password, from an external vault. We're providing a built-in integration with Kubernetes secrets as well as an SPI allowing integrating with any vault provider.&lt;/p&gt; &lt;p&gt;In the future we will also provide the option to encrypt other more dynamic credentials at rest in the database.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://issues.jboss.org/browse/KEYCLOAK-3205"&gt;JIRA - Vault&lt;/li&gt; &lt;li&gt;&lt;a href="https://issues.jboss.org/browse/KEYCLOAK-10774"&gt;JIRA - Encryption at rest&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;User Profile&lt;/h3&gt; &lt;p&gt;Currently there's no single place to define user profiles for a realm. To resolve this we are planning to introduce the Profile SPI, which will make it possible to define a user profile for a realm. It will be possible to define mandatory as well as optional attributes and also add validation to the attributes.&lt;/p&gt; &lt;p&gt;The built-in Profile SPI provider will make it possible to declaratively define the user profile for a realm and we also aim to have an editor in the admin console.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://issues.jboss.org/browse/KEYCLOAK-2966"&gt;JIRA&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;Observerability&lt;/h3&gt; &lt;p&gt;Keycloak already comes with basic support for metrics and health endpoints provided by the underlying WildFly container. We plan to document how to enable this as well as extend with Keycloak specific metrics and health checks. If you would like to try this out today check the WildFly documentation.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://issues.jboss.org/browse/KEYCLOAK-8288"&gt;JIRA&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;Continuous Delivery&lt;/h3&gt; &lt;p&gt;Over the last few months the team has invested a significant amount of time into automated testing and builds. This will pay of in the long run as we will need to spend less time on releases and will also make sure Keycloak is always release ready. In fact we're taking this as far as not allowing maintainers to manually merge PRs anymore, but rather have created a bot called the Merge Monster that will merge PRs automatically after they have been both manually reviewed and all tests have passed.&lt;/p&gt; &lt;h3&gt;Keycloak.X&lt;/h3&gt; &lt;p&gt;It's 5 years since the first Keycloak release so high time for some rearchitecting. More details coming soon!&lt;/p&gt; &lt;h3&gt;Kanban Planning Board&lt;/h3&gt; &lt;p&gt;For more insight and details into what we are working on and our backlog, check out our &lt;a href="https://issues.jboss.org/secure/RapidBoard.jspa?rapidView=4740&amp;quickFilter=17938&amp;quickFilter=17950"&gt; Kanban Planning Board&lt;/a&gt;.&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/XDWUfmSnn4Y" height="1" width="1" alt=""/&gt;</content><summary>New Account Console and Account REST API The current account console is getting dated. It is also having issues around usability and being hard to extend. For this reason we had the UXD team at Red Hat develop wireframes for a new account console. The new console is being implemented with React.js providing a better user experience as well as making it easier to extend and customise. JIRA - Accoun...</summary><dc:creator>Stian Thorgersen</dc:creator><dc:date>2019-09-03T00:00:00Z</dc:date><feedburner:origLink>https://www.keycloak.org/2019/09/2019-roadmap.html</feedburner:origLink></entry><entry><title>DevNation Live: Quarkus: Supersonic, subatomic Java</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/ZppQav7MrlM/" /><category term="devnation" scheme="searchisko:content:tags" /><category term="DevNation Live" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Java" scheme="searchisko:content:tags" /><category term="Kubernetes" scheme="searchisko:content:tags" /><category term="quarkus" scheme="searchisko:content:tags" /><author><name>Editorial Team</name></author><id>searchisko:content:id:jbossorg_blog-devnation_live_quarkus_supersonic_subatomic_java</id><updated>2019-09-02T07:00:11Z</updated><published>2019-09-02T07:00:11Z</published><content type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/devnation/?page=0"&gt;DevNation Live tech talks&lt;/a&gt; are hosted by the Red Hat technologists who create our products. These sessions include real solutions and code and sample projects to help you get started. In this talk, you’ll learn about &lt;a href="https://developers.redhat.com/blog/2019/03/07/quarkus-next-generation-kubernetes-native-java-framework/"&gt;Quarkus&lt;/a&gt; from &lt;a href="https://developers.redhat.com/node/204405/"&gt;Burr Sutter&lt;/a&gt;, &lt;a href="https://developers.redhat.com/blog/author/jgreene/"&gt;Jason Greene&lt;/a&gt;, and &lt;a href="https://developers.redhat.com/blog/author/yanaga/"&gt;Edson Yanaga&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;In this session, we’ll demonstrate how you can optimize your enterprise Java apps, your APIs, your microservices, and your “serverless functions” for a &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt;/&lt;a href="https://developers.redhat.com/openshift/"&gt;OpenShift&lt;/a&gt; environment—vastly smaller, vastly faster, and fundamentally more scalable.&lt;/p&gt; &lt;p&gt;Watch the complete presentation:&lt;/p&gt; &lt;p&gt;&lt;iframe src="https://www.youtube.com/embed/7G_r1iyrn2c" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"&gt;&lt;/iframe&gt;&lt;/p&gt; &lt;h3&gt;Learn more&lt;/h3&gt; &lt;p class="selectionShareable"&gt;Join us at an upcoming &lt;a href="https://developers.redhat.com/events/"&gt;developer event&lt;/a&gt;, and see our collection of &lt;a href="https://developers.redhat.com/devnation/?page=0"&gt;past DevNation Live tech talks&lt;/a&gt;&lt;a href="https://developers.redhat.com/events/"&gt;.&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F09%2F02%2Fdevnation-live-quarkus-supersonic-subatomic-java%2F&amp;#38;linkname=DevNation%20Live%3A%20Quarkus%3A%20Supersonic%2C%20subatomic%20Java" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F09%2F02%2Fdevnation-live-quarkus-supersonic-subatomic-java%2F&amp;#38;linkname=DevNation%20Live%3A%20Quarkus%3A%20Supersonic%2C%20subatomic%20Java" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F09%2F02%2Fdevnation-live-quarkus-supersonic-subatomic-java%2F&amp;#38;linkname=DevNation%20Live%3A%20Quarkus%3A%20Supersonic%2C%20subatomic%20Java" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F09%2F02%2Fdevnation-live-quarkus-supersonic-subatomic-java%2F&amp;#38;linkname=DevNation%20Live%3A%20Quarkus%3A%20Supersonic%2C%20subatomic%20Java" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F09%2F02%2Fdevnation-live-quarkus-supersonic-subatomic-java%2F&amp;#38;linkname=DevNation%20Live%3A%20Quarkus%3A%20Supersonic%2C%20subatomic%20Java" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F09%2F02%2Fdevnation-live-quarkus-supersonic-subatomic-java%2F&amp;#38;linkname=DevNation%20Live%3A%20Quarkus%3A%20Supersonic%2C%20subatomic%20Java" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F09%2F02%2Fdevnation-live-quarkus-supersonic-subatomic-java%2F&amp;#38;linkname=DevNation%20Live%3A%20Quarkus%3A%20Supersonic%2C%20subatomic%20Java" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F09%2F02%2Fdevnation-live-quarkus-supersonic-subatomic-java%2F&amp;#038;title=DevNation%20Live%3A%20Quarkus%3A%20Supersonic%2C%20subatomic%20Java" data-a2a-url="https://developers.redhat.com/blog/2019/09/02/devnation-live-quarkus-supersonic-subatomic-java/" data-a2a-title="DevNation Live: Quarkus: Supersonic, subatomic Java"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/09/02/devnation-live-quarkus-supersonic-subatomic-java/"&gt;DevNation Live: Quarkus: Supersonic, subatomic Java&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/ZppQav7MrlM" height="1" width="1" alt=""/&gt;</content><summary>DevNation Live tech talks are hosted by the Red Hat technologists who create our products. These sessions include real solutions and code and sample projects to help you get started. In this talk, you’ll learn about Quarkus from Burr Sutter, Jason Greene, and Edson Yanaga. In this session, we’ll demonstrate how you can optimize your enterprise Java apps, your APIs, your microservices, and your “se...</summary><dc:creator>Editorial Team</dc:creator><dc:date>2019-09-02T07:00:11Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/09/02/devnation-live-quarkus-supersonic-subatomic-java/</feedburner:origLink></entry><entry><title>5 Questions Everyone's Asking About Microservices (Question 4)</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/8WkgVAe0Hcs/5-questions-everyones-asking-about-microservices-question4.html" /><category term="AppDev" scheme="searchisko:content:tags" /><category term="best practices" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_ericschabell" scheme="searchisko:content:tags" /><category term="FUSE" scheme="searchisko:content:tags" /><category term="JBoss" scheme="searchisko:content:tags" /><category term="JBossAMQ" scheme="searchisko:content:tags" /><author><name>Eric D. Schabell</name></author><id>searchisko:content:id:jbossorg_blog-5_questions_everyone_s_asking_about_microservices_question_4</id><updated>2019-09-02T14:26:49Z</updated><published>2019-09-02T05:00:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;a href="https://1.bp.blogspot.com/-i6x1EOlxWyE/XVQFqTEqWhI/AAAAAAAAvLk/4p4gtw-bjm4BQAwWePd4zeAQ0Vbg3984ACLcBGAs/s1600/questions.jpg" style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="666" data-original-width="1000" height="213" src="https://1.bp.blogspot.com/-i6x1EOlxWyE/XVQFqTEqWhI/AAAAAAAAvLk/4p4gtw-bjm4BQAwWePd4zeAQ0Vbg3984ACLcBGAs/s320/questions.jpg" width="320" /&gt;&lt;/a&gt;When discussing the development impact on existing applications while transitioning to microservices, there are five questions that keep popping up in one form or another. They are the same regardless of the size of the organization and seem to become part of strategy discussions later in the process as organizations move towards microservice architectures. &lt;br /&gt;&lt;br /&gt;These articles cover questions that everyone should ask about microservices. Their based on experiences from interactions with organizations in the process of conquering microservices for existing development and for delivering modern applications.&lt;br /&gt;&lt;br /&gt;Previously we covered three questions; &lt;a href="http://www.schabell.org/2019/08/5-questions-everyones-asking-about-microservices-question1.html" target="_blank"&gt;the performance impact of microservices&lt;/a&gt;,&amp;nbsp; a question on &lt;a href="http://www.schabell.org/2019/08/5-questions-everyones-asking-about-microservices-question2.html" target="_blank"&gt;state and monoliths&lt;/a&gt;, and one about &lt;a href="https://www.schabell.org/2019/08/5-questions-everyones-asking-about-microservices-question3.html" target="_blank"&gt;data and microservices&lt;/a&gt;. In this fourth article covers a question around testing stateful microservices.&lt;br /&gt;&lt;a name='more'&gt;&lt;/a&gt;&lt;div style="text-align: left;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;h3 style="text-align: left;"&gt;Testing microservices&lt;/h3&gt;Assuming all goes well, everyone eventually gets to the point of testing all these new fancy distributed microservices. Then comes the realization that data source state information's spread across the application landscape, raising the following.&lt;br /&gt;&lt;br /&gt;&lt;i&gt;“How can the state of a main application be transferred from production to a test environment when&amp;nbsp; there are many data sources tied to stateful services in production?”&lt;/i&gt;&lt;br /&gt;&lt;br /&gt;&lt;table cellpadding="0" cellspacing="0" class="tr-caption-container" style="float: right; margin-left: 1em; text-align: right;"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-FprciQaKqVs/XW0l8KHXsfI/AAAAAAAAvMM/YceD3TgfZ20oqfwDhOSECYgW80_8P6tcQCLcBGAs/s1600/Screenshot%2B2019-09-02%2Bat%2B16.18.13.png" imageanchor="1" style="clear: right; margin-bottom: 1em; margin-left: auto; margin-right: auto;"&gt;&lt;img border="0" data-original-height="992" data-original-width="1600" height="198" src="https://1.bp.blogspot.com/-FprciQaKqVs/XW0l8KHXsfI/AAAAAAAAvMM/YceD3TgfZ20oqfwDhOSECYgW80_8P6tcQCLcBGAs/s320/Screenshot%2B2019-09-02%2Bat%2B16.18.13.png" width="320" /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="tr-caption" style="text-align: center;"&gt;(Photo: Christina Lin, DevConf.US 2019)&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;In a microservices world, each microservice is operating as if it’s part of another business external to your organization. As you're having a business-to-business relationship, the microservice development teams are forced to maintain a strong API and have their own test suite. We have to realize that a good microservice should be a black box. &lt;br /&gt;&lt;div style="text-align: right;"&gt;&lt;/div&gt;&lt;br /&gt;Few external business partners rarely have all the data, they only have the data they need for testing purposes. This same principle applies to internal teams developing and maintaining microservices in your organization. Testing tends to happen more in production in this new world, which is why we see the value of a service mesh technology such as &lt;a href="https://istio.io/docs/concepts/what-is-istio/" target="_blank"&gt;Istio&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;Going a bit more advanced with your solution, it’s possible to use &lt;a href="https://debezium.io/" target="_blank"&gt;Debezium&lt;/a&gt; to replicate data through a common Kafka backbone, anonymize it and drop it to the locations needed by various independent microservice development teams (the business partners internal to your organization). &lt;br /&gt;&lt;br /&gt;Next time in this series of articles, a look at using API management or service mesh.&lt;br /&gt;&lt;br /&gt;&lt;span style="font-size: small;"&gt;&lt;i&gt;(article co-authored with &lt;a href="https://twitter.com/burrsutter" target="_blank"&gt;Burr Sutter)&amp;nbsp;&lt;/a&gt;&lt;/i&gt;&lt;/span&gt;&lt;/div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=C9vgGy2Pmxo:k35-dZ83sgk:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=C9vgGy2Pmxo:k35-dZ83sgk:63t7Ie-LG7Y"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=63t7Ie-LG7Y" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=C9vgGy2Pmxo:k35-dZ83sgk:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=C9vgGy2Pmxo:k35-dZ83sgk:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=C9vgGy2Pmxo:k35-dZ83sgk:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=C9vgGy2Pmxo:k35-dZ83sgk:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=C9vgGy2Pmxo:k35-dZ83sgk:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=C9vgGy2Pmxo:k35-dZ83sgk:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=C9vgGy2Pmxo:k35-dZ83sgk:qj6IDK7rITs"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=qj6IDK7rITs" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=C9vgGy2Pmxo:k35-dZ83sgk:gIN9vFwOqvQ"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=C9vgGy2Pmxo:k35-dZ83sgk:gIN9vFwOqvQ" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/schabell/jboss/~4/C9vgGy2Pmxo" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/8WkgVAe0Hcs" height="1" width="1" alt=""/&gt;</content><summary>When discussing the development impact on existing applications while transitioning to microservices, there are five questions that keep popping up in one form or another. They are the same regardless of the size of the organization and seem to become part of strategy discussions later in the process as organizations move towards microservice architectures. These articles cover questions that ever...</summary><dc:creator>Eric D. Schabell</dc:creator><dc:date>2019-09-02T05:00:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/C9vgGy2Pmxo/5-questions-everyones-asking-about-microservices-question4.html</feedburner:origLink></entry><entry><title>JBoss Weekly Editorial 30 August 2019</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/DyWhrlmKnPM/jboss-weekly-editorial-30-august-2019" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_weeklyeditorial" scheme="searchisko:content:tags" /><category term="keycloak" scheme="searchisko:content:tags" /><category term="microservices" scheme="searchisko:content:tags" /><category term="quarkus" scheme="searchisko:content:tags" /><category term="weekly_editorial" scheme="searchisko:content:tags" /><author><name>Jason Porter</name></author><id>searchisko:content:id:jbossorg_blog-jboss_weekly_editorial_30_august_2019</id><updated>2019-09-03T15:59:19Z</updated><published>2019-08-30T18:40:00Z</published><content type="html">&lt;!-- [DocumentBodyStart:4724a137-eea0-441d-8e13-b0a81c61a664] --&gt;&lt;div class="jive-rendered-content"&gt;&lt;div&gt;&lt;div&gt;&lt;div class="sectionbody"&gt;&lt;div class="paragraph"&gt;&lt;p&gt;Welcome everyone! We hope everyone is excited (or enjoyed if it has already passed) for the Labor Day weekend if you&amp;#8217;re in the U.S. There are some great blog posts over the past couple of weeks we want to highlight and a couple of releases as well.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="sect1"&gt;&lt;h2&gt;Releases&lt;/h2&gt;&lt;div class="sectionbody"&gt;&lt;div class="paragraph"&gt;&lt;p&gt;There are two releases we want to highlight in this editorial. The first is the &lt;a class="jive-link-external-small" href="https://www.keycloak.org/2019/08/keycloak-700-released.html" rel="nofollow"&gt;Keycloak 7.0.0 release&lt;/a&gt;! You can of course find all the information you need in the &lt;a class="jive-link-external-small" href="https://www.keycloak.org/docs/latest/release_notes/index.html" rel="nofollow"&gt;release notes&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;&lt;div class="paragraph"&gt;&lt;p&gt;Next is the update and release of the new &lt;a class="jive-link-external-small" href="https://camel.apache.org/" rel="nofollow"&gt;Apache Camel website&lt;/a&gt;. The website has had a pretty major overhaul with a new design, graphics, layout and look toward the mobile experience. The website source is hosted on &lt;a class="jive-link-external-small" href="https://github.com/apache/camel-website/" rel="nofollow"&gt;GitHub&lt;/a&gt; should you wish to contribute.&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="sect1"&gt;&lt;h2&gt;&lt;/h2&gt;&lt;h2&gt;Blogs&lt;/h2&gt;&lt;div class="sectionbody"&gt;&lt;div class="paragraph"&gt;&lt;p&gt;Oddly enough, the blogsphere has been a little quiet the past couple of weeks, must have something to do with summer.&lt;/p&gt;&lt;/div&gt;&lt;div class="sect2"&gt;&lt;h3&gt;&lt;/h3&gt;&lt;h3&gt;Eric Schabell&lt;/h3&gt;&lt;div class="paragraph"&gt;&lt;p&gt;As is normal, Eric Schabell has been very busy over at his blog. We&amp;#8217;d like to mention of few of the things he&amp;#8217;s been writing about:&lt;/p&gt;&lt;/div&gt;&lt;div class="ulist"&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;a class="jive-link-external-small" href="http://www.schabell.org/2019/08/5-questions-everyones-asking-about-microservices-question2.html" rel="nofollow"&gt;5 Questions Everyone&amp;#8217;s Asking About Microservices (Question 2)&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a class="jive-link-external-small" href="http://www.schabell.org/2019/08/5-questions-everyones-asking-about-microservices-question3.html" rel="nofollow"&gt;5 Questions Everyone&amp;#8217;s Asking About Microservices (Question 3)&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a class="jive-link-external-small" href="http://www.schabell.org/2019/08/devconfus-2019-7-steps-to-expanding-appdev-toolbox-slides.html" rel="nofollow"&gt;DevConf.US 2019 - 7 Steps to Expanding Your AppDev Toolbox (slides)&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a class="jive-link-external-small" href="http://www.schabell.org/2019/08/devconfus-2019-how-to-jump-start-your-career-in-open-source-slides.html" rel="nofollow"&gt;DevConf.US 2019 - How to Jump Start Your Career in Open Source (slides)&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a class="jive-link-external-small" href="http://www.schabell.org/2019/08/devconfus-2019-3-pitfalls-everyone-ignores-with-microservices-slides.html" rel="nofollow"&gt;DevConf.US 2019 - 3 Pitfalls Everyone Ignores with Microservices (slides)&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="sect2"&gt;&lt;h3&gt;&lt;/h3&gt;&lt;h3&gt;Red Hat Developer Blog&lt;/h3&gt;&lt;div class="paragraph"&gt;&lt;p&gt;The Red Hat Developer blog has some great information if you haven&amp;#8217;t been there. We&amp;#8217;re showcasing just few from the past few weeks:&lt;/p&gt;&lt;/div&gt;&lt;div class="ulist"&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/08/30/easily-deploy-node-js-applications-to-red-hat-openshift-using-nodeshift/" rel="nofollow"&gt;Easily deploy Node.js applications to Red Hat OpenShift using Nodeshift&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/08/29/create-your-first-application-with-kogito/" rel="nofollow"&gt;Create your first application with Kogito&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/08/26/10-quarkus-videos-to-get-you-up-to-speed-with-supersonic-subatomic-java/" rel="nofollow"&gt;10 Quarkus videos to get you up to speed with supersonic, subatomic Java&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div class="paragraph"&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;That will do it for this edition of the editorial, thanks for being with us!&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;!-- [DocumentBodyEnd:4724a137-eea0-441d-8e13-b0a81c61a664] --&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/DyWhrlmKnPM" height="1" width="1" alt=""/&gt;</content><summary>Welcome everyone! We hope everyone is excited (or enjoyed if it has already passed) for the Labor Day weekend if you’re in the U.S. There are some great blog posts over the past couple of weeks we want to highlight and a couple of releases as well.   Releases There are two releases we want to highlight in this editorial. The first is the Keycloak 7.0.0 release! You can of course find all the infor...</summary><dc:creator>Jason Porter</dc:creator><dc:date>2019-08-30T18:40:00Z</dc:date><feedburner:origLink>https://developer.jboss.org/blogs/weekly-editorial/2019/08/30/jboss-weekly-editorial-30-august-2019</feedburner:origLink></entry><entry><title>Enhanced Audit Logging in WildFly Elytron - RFC Support and Reliabiliity/Speed Customization Update</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/xElKamzZguI/enhanced-audit-logging-in-wildfly.html" /><category term="audit-logging" scheme="searchisko:content:tags" /><category term="auditing" scheme="searchisko:content:tags" /><category term="Elytron" scheme="searchisko:content:tags" /><category term="feed_group_name_wildfly" scheme="searchisko:content:tags" /><category term="feed_name_jucook" scheme="searchisko:content:tags" /><category term="logging" scheme="searchisko:content:tags" /><category term="RFC3164" scheme="searchisko:content:tags" /><category term="RFC5424" scheme="searchisko:content:tags" /><category term="wildfly" scheme="searchisko:content:tags" /><author><name>Justin Cook</name></author><id>searchisko:content:id:jbossorg_blog-enhanced_audit_logging_in_wildfly_elytron_rfc_support_and_reliabiliity_speed_customization_update</id><updated>2019-08-30T14:26:00Z</updated><published>2019-08-30T14:26:00Z</published><content type="html">&lt;!DOCTYPE html&gt;&lt;html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang=""&gt;&lt;head&gt; &lt;meta charset="utf-8" /&gt; &lt;meta name="generator" content="pandoc" /&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" /&gt; &lt;title&gt;rfc_support_reliability_customization_final&lt;/title&gt; &lt;style type="text/css"&gt; code{white-space: pre-wrap;} span.smallcaps{font-variant: small-caps;} span.underline{text-decoration: underline;} div.column{display: inline-block; vertical-align: top; width: 50%;} &lt;/style&gt; &lt;style type="text/css"&gt;a.sourceLine { display: inline-block; line-height: 1.25; } a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; } a.sourceLine:empty { height: 1.2em; position: absolute; } .sourceCode { overflow: visible; } code.sourceCode { white-space: pre; position: relative; } div.sourceCode { margin: 1em 0; } pre.sourceCode { margin: 0; } @media screen { div.sourceCode { overflow: auto; } } @media print { code.sourceCode { white-space: pre-wrap; } a.sourceLine { text-indent: -1em; padding-left: 1em; } } pre.numberSource a.sourceLine { position: relative; } pre.numberSource a.sourceLine:empty { position: absolute; } pre.numberSource a.sourceLine::before { content: attr(data-line-number); position: absolute; left: -5em; text-align: right; vertical-align: baseline; border: none; pointer-events: all; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; padding: 0 4px; width: 4em; color: #aaaaaa; } pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; } div.sourceCode { } @media screen { a.sourceLine::before { text-decoration: underline; } } code span.al { color: #ff0000; font-weight: bold; } /* Alert */ code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */ code span.at { color: #7d9029; } /* Attribute */ code span.bn { color: #40a070; } /* BaseN */ code span.bu { } /* BuiltIn */ code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */ code span.ch { color: #4070a0; } /* Char */ code span.cn { color: #880000; } /* Constant */ code span.co { color: #60a0b0; font-style: italic; } /* Comment */ code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */ code span.do { color: #ba2121; font-style: italic; } /* Documentation */ code span.dt { color: #902000; } /* DataType */ code span.dv { color: #40a070; } /* DecVal */ code span.er { color: #ff0000; font-weight: bold; } /* Error */ code span.ex { } /* Extension */ code span.fl { color: #40a070; } /* Float */ code span.fu { color: #06287e; } /* Function */ code span.im { } /* Import */ code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */ code span.kw { color: #007020; font-weight: bold; } /* Keyword */ code span.op { color: #666666; } /* Operator */ code span.ot { color: #007020; } /* Other */ code span.pp { color: #bc7a00; } /* Preprocessor */ code span.sc { color: #4070a0; } /* SpecialChar */ code span.ss { color: #bb6688; } /* SpecialString */ code span.st { color: #4070a0; } /* String */ code span.va { color: #19177c; } /* Variable */ code span.vs { color: #4070a0; } /* VerbatimString */ code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */ &lt;/style&gt; &lt;style&gt;table { border-cllapse: collapse; width: 100%; } th { background-color: #077992; color: white; } td { padding: 1em; } .even { background-color: #424242; } &lt;/style&gt; &lt;!--[if lt IE 9]&gt; &lt;script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"&gt;&lt;/script&gt; &lt;![endif]--&gt;&lt;/head&gt;&lt;body&gt;&lt;h1 id="enhancing-audit-logging-in-wildfly-elytron---rfc-support-and-configuring-reconnects-update"&gt;Enhancing Audit Logging in WildFly Elytron - RFC Support and Configuring Reconnects Update&lt;/h1&gt;&lt;h2 id="overview"&gt;Overview&lt;/h2&gt;&lt;p&gt;In WildFly 18, audit logging in WildFly Elytron has now been enhanced with additional audit logging capabilities, with additional RFC Support and the ability to configure how many times Elytron should attempt to send messages to a syslog server when an error sending is encountered. This blog post will give an overview about the enhancements that have been added and some examples on how to use these new enhancements. Some sections of this blog post have already been detailed in the original blog post detailing the enhancements that were being worked on, available at: https://justinwildfly.blogspot.com/2019/06/enhanced-audit-logging-in-wildfly.html&lt;/p&gt;&lt;h2 id="additional-rfc-support"&gt;Additional RFC Support&lt;/h2&gt;&lt;h3 id="rfc-formats"&gt;RFC Formats&lt;/h3&gt;&lt;p&gt;WildFly Elytron’s syslog audit logging currently only supports RFC 5424, but some users may wish to use the legacy RFC 3164. Elytron is now being enhanced to provide support for this additional RFC through the addition of a &lt;code&gt;syslog-format&lt;/code&gt; parameter. This new parameter will default to the current supported value of RFC 5424 and will support the value of RFC 3164, or can be explicitly set as RFC 5424. The parameter can be used on the WildFly CLI in the following ways:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;/subsystem=elytron/syslog-audit-log=syslog-test:add(server-address=&amp;quot;127.0.0.1&amp;quot;,port=10999,transport=UDP,host-name=localhost,syslog-format=RFC3164)&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;/subsystem=elytron/syslog-audit-log=syslog-test:add(server-address=&amp;quot;127.0.0.1&amp;quot;,port=10999,transport=UDP,host-name=localhost,syslog-format=RFC5424)&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;/subsystem=elytron/syslog-audit-log=syslog-test:add(server-address=&amp;quot;127.0.0.1&amp;quot;,port=10999,transport=UDP,host-name=localhost)&lt;/code&gt;&lt;/pre&gt;&lt;h3 id="additional-rfc-events"&gt;Additional RFC Events&lt;/h3&gt;&lt;h4 id="rfc3164syslogevent-and-rfc5424syslogevent"&gt;Rfc3164SyslogEvent and Rfc5424SyslogEvent&lt;/h4&gt;&lt;p&gt;Two new publicly accessible SecurityEvent classes have been added to WildFly Elytron, along with the publicly accessible abstract class SyslogAuditEvent. These new events can be used to provide more information on what is being sent to the syslog-server, showing the &lt;code&gt;syslog-format&lt;/code&gt; along with the standard &lt;code&gt;security-identity&lt;/code&gt; and &lt;code&gt;event-time&lt;/code&gt; values.&lt;/p&gt;&lt;h4 id="audit-logging-enabled-message"&gt;Audit Logging Enabled Message&lt;/h4&gt;&lt;p&gt;WildFly Elytron will now send a syslog message to the syslog server when the syslog audit logging is enabled, to allow the user to verify their connection and syslog server are both working. This new message will consist of “Elytron audit logging enabled with RFC format:” followed by the syslog-format that has been set, with a priority of &lt;code&gt;Informational&lt;/code&gt;.&lt;/p&gt;&lt;h2 id="reliability-vs-speed"&gt;Reliability vs Speed&lt;/h2&gt;&lt;p&gt;Users will now be able to limit how many times WildFly Elytron will attempt to resend a message to the syslog-server, as compared to currently trying to resend the message forever. This new parameter is called “reconnect-attempts” and is an optional parameter on the WildFly CLI with a default value of &lt;code&gt;-1&lt;/code&gt;. The following values available to the parameter and their use are:&lt;/p&gt;&lt;table&gt;&lt;colgroup&gt;&lt;col style="width: 50%" /&gt;&lt;col style="width: 50%" /&gt;&lt;/colgroup&gt;&lt;thead&gt;&lt;tr class="header"&gt;&lt;th style="text-align: center;"&gt;Value&lt;/th&gt;&lt;th style="text-align: center;"&gt;Use&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr class="odd"&gt;&lt;td style="text-align: center;"&gt;-1&lt;/td&gt;&lt;td style="text-align: center;"&gt;Always attempt to send audit messages, regardless of the amount of previous failures&lt;/td&gt;&lt;/tr&gt;&lt;tr class="even"&gt;&lt;td style="text-align: center;"&gt;0&lt;/td&gt;&lt;td style="text-align: center;"&gt;Only attempt to send a single message, which would be the initial connection message, before closing the endpoint if there was an error sending&lt;/td&gt;&lt;/tr&gt;&lt;tr class="odd"&gt;&lt;td style="text-align: center;"&gt;Positive integer&lt;/td&gt;&lt;td style="text-align: center;"&gt;Closes the endpoint if there messages failed to send n times&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;On the WildFly CLI, these values would look like, with infinite, no resends, n resends, default of infinite:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;/subsystem=elytron/syslog-audit-log=syslog-test:add(server-address=&amp;quot;127.0.0.1&amp;quot;,port=10999,transport=UDP,host-name=localhost,reconnect-attempts=-1)&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;/subsystem=elytron/syslog-audit-log=syslog-test:add(server-address=&amp;quot;127.0.0.1&amp;quot;,port=10999,transport=UDP,host-name=localhost,reconnect-attempts=0)&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;/subsystem=elytron/syslog-audit-log=syslog-test:add(server-address=&amp;quot;127.0.0.1&amp;quot;,port=10999,transport=UDP,host-name=localhost,reconnect-attempts=50)&lt;/code&gt;&lt;/pre&gt;&lt;pre&gt;&lt;code&gt;/subsystem=elytron/syslog-audit-log=syslog-test:add(server-address=&amp;quot;127.0.0.1&amp;quot;,port=10999,transport=UDP,host-name=localhost)&lt;/code&gt;&lt;/pre&gt;&lt;h2 id="summary"&gt;Summary&lt;/h2&gt;&lt;p&gt;This blog post provides some information about enhancements to WildFly Elytron’s audit logging, in particular it talks about the addition of a syslog-format parameter and a reconnect-attempts parameter for syslog audit logging, two new SecurityEvents and a new abstract SecurityEvent, and an initial connect message.&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/xElKamzZguI" height="1" width="1" alt=""/&gt;</content><summary>rfc_support_reliability_customization_final Enhancing Audit Logging in WildFly Elytron - RFC Support and Configuring Reconnects Update Overview In WildFly 18, audit logging in WildFly Elytron has now been enhanced with additional audit logging capabilities, with additional RFC Support and the ability to configure how many times Elytron should attempt to send messages to a syslog server when an err...</summary><dc:creator>Justin Cook</dc:creator><dc:date>2019-08-30T14:26:00Z</dc:date><feedburner:origLink>https://justinwildfly.blogspot.com/2019/08/enhanced-audit-logging-in-wildfly.html</feedburner:origLink></entry><entry><title>The clean break of Open Virtual Network from Open vSwitch</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/EH196gny7bs/" /><category term="cloud" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Networking" scheme="searchisko:content:tags" /><category term="open virtual network" scheme="searchisko:content:tags" /><category term="Open vSwitch" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><author><name>Mark Michelson</name></author><id>searchisko:content:id:jbossorg_blog-the_clean_break_of_open_virtual_network_from_open_vswitch</id><updated>2019-08-30T07:01:21Z</updated><published>2019-08-30T07:01:21Z</published><content type="html">&lt;p&gt;After loads of email and IRC discussions, the &lt;a href="https://github.com/ovn-org/ovn"&gt;Open Virtual Network (OVN) source code&lt;/a&gt; has been separated from the &lt;a href="https://github.com/openvswitch/ovs"&gt;Open vSwitch (OVS) source code&lt;/a&gt;, and the two projects now operate independently. In this article, we&amp;#8217;ll explain the reasons for separating OVN from OVS, the technical aspects of the split, and the upcoming challenges for the OVN project.&lt;span id="more-619907"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Background&lt;/h2&gt; &lt;p&gt;OVN was initially announced on the OVS developers mailing list in January of 2015. From the initial &lt;a href="https://mail.openvswitch.org/pipermail/ovs-dev/2015-January/293922.html"&gt;email announcement&lt;/a&gt;:&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;&amp;#8220;OVN will not require a special build of OVS or OVN-specific changes to ovs-vswitchd or ovsdb-server. OVN components will be part of the Open vSwitch source and binary distributions.&amp;#8221;&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;The decision to include OVN in the same source distribution of OVS was done mostly out of convenience. By including it in the same source distribution, OVN could make use of bleeding-edge features of OVS without issue. OVS wouldn&amp;#8217;t need to be modified to export libraries for external programs&amp;#8217; use. All that was needed to be done was to make an OVN subdirectory in the OVS project and put some code in there. That said, there were discussions about OVN existing in a separate repo from the beginning, and it was expected that eventually OVN would split out into its own repo. Thus, the issues became: When would it become necessary, and who would be willing to put in the work?&lt;/p&gt; &lt;h2&gt;The present&lt;/h2&gt; &lt;p&gt;Since the initial creation of OVN in 2015, the project has matured, and cloud management services (CMSes) have begun adopting it. At Red Hat, &lt;a href="https://www.openstack.org/"&gt;OpenStack&lt;/a&gt; and &lt;a href="https://developers.redhat.com/openshift/"&gt;Openshift&lt;/a&gt; both make use of OVN for defining their virtual networks. From their point of view, they interact directly with OVN, while OVS performs more &amp;#8220;under the hood&amp;#8221; work. OVN is constantly getting vital new features, while OVS gets changes they don&amp;#8217;t care nearly as much about. Also, from a CMS point of view, OVS is seen as &amp;#8220;stable.&amp;#8221; There&amp;#8217;s not as much incentive to want to upgrade the version of OVS they run on. OVS operates on a six-month release cycle, but CMSes are interested in getting the new OVN features more quickly. CMSes are satisfied with the current feature set of OVS and would prefer not to have to update OVS if they do not have to. Instead, they have to wait six months for the OVN features to be available, and then they&amp;#8217;re forced to update OVS beyond what they want to be using.&lt;/p&gt; &lt;h2&gt;Three stages of separation&lt;/h2&gt; &lt;p&gt;Based on this situation, discussion about separating OVN from OVS has been going on for a long time. Earlier in 2019, Red Hat made the resolution to put in the legwork to get OVN separated from OVS. The first step was to work through the technical aspects of the split. Here is a &lt;a href="https://mail.openvswitch.org/pipermail/ovs-dev/2018-December/354513.html"&gt;mailing list post&lt;/a&gt; I created outlining potential strategies for performing the separation. In the end, we came up with a three-stage plan for separating OVN from OVS.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Stage 1: Separate the packaging of OVN from OVS.&lt;/li&gt; &lt;li&gt;Stage 2: Create a separate OVN source repo, including OVS as a Git subtree.&lt;/li&gt; &lt;li&gt;Stage 3: Eliminate the OVS subtree, allowing compilation of OVN using a remote installation of OVS.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;We &lt;a href="https://mail.openvswitch.org/pipermail/ovs-dev/2019-January/354924.html"&gt;completed Stage 1&lt;/a&gt; in January. A new spec file was added to the OVS distribution, and OVN&amp;#8217;s RPMs were moved to this spec file. The package names also changed at this point. When OVS 2.11 released, rather than having &lt;em&gt;openvswitch-ovn-central&lt;/em&gt; and &lt;em&gt;openvswitch-ovn-host packages&lt;/em&gt;, we now created &lt;em&gt;ovn-central&lt;/em&gt; and &lt;em&gt;ovn-host&lt;/em&gt; packages. Aside from the change in the package name, this step likely was not noticeable to users. The new package was designed so that an upgrade would transparently install the new packages.&lt;/p&gt; &lt;p&gt;For Stage 2, we performed a couple of &lt;a href="https://mail.openvswitch.org/pipermail/ovs-dev/2019-February/356365.html"&gt;trial&lt;/a&gt; &lt;a href="https://mail.openvswitch.org/pipermail/ovs-dev/2019-March/357586.html"&gt;runs&lt;/a&gt; separating OVN from OVS earlier this year. However, we chose not to go live with this change until after the OVS 2.12 branch was created. This way, we had a clear separation point for OVN development to happen in its own repo. The OVS 2.12 branch was created on July 22, and we performed the split the following week. Since the split, all OVN developers have targeted their new features to the new OVN repo. When OVS 2.12.0 releases, it will be the final release of OVS that also includes a companion OVN version. With Stage 2 complete, OVN has the freedom to change its release cadence; however, it also has the responsibility to maintain compatibility with multiple versions of OVS.&lt;/p&gt; &lt;p&gt;Stage 3 is currently &lt;a href="https://mail.openvswitch.org/pipermail/ovs-dev/2019-August/361799.html"&gt;under review&lt;/a&gt; and likely will be merged very soon. Including OVS as a Git subtree was a good stopgap for convenience, but it makes building and testing OVN a bit odd. Specifically, keeping a Git subtree up to date is not as straightforward as just keeping a separate repo on your system up to date as necessary. When running unit tests, due to the way that GNU autotest works, those tests would be run from within the OVS subtree and from OVN&amp;#8217;s tests/ directory. This could lead to annoyances when attempting to run specific OVN tests. With OVS separated out, that is no longer an issue, and it makes for much quicker testing of OVN.&lt;/p&gt; &lt;p&gt;An unstated (and obvious) Stage 4 is to remove the OVN code from the OVS repo. We have a &lt;a href="https://mail.openvswitch.org/pipermail/ovs-dev/2019-August/361704.html"&gt;patch series&lt;/a&gt; on the mailing list that does this, but it is still awaiting approval.&lt;/p&gt; &lt;h2&gt;The future&lt;/h2&gt; &lt;p&gt;The &amp;#8220;physical&amp;#8221; aspect of separating OVN from OVS is complete. However, we still face many challenges going forward. The biggest problem is coming up with policies for maintaining compatibility between OVN and OVS. I have started a &lt;a href="https://mail.openvswitch.org/pipermail/ovs-dev/2019-August/361435.html"&gt;mailing list discussion&lt;/a&gt; with a document that lays out a potential solution to this.&lt;/p&gt; &lt;p&gt;The question of how we plan to version OVN from here on is also an issue. Given how CMSes are hoping to be able to use newer OVN features more rapidly, it may make sense to release new versions of OVN more quickly than every six months. Previously, OVN was included as part of each OVS release. So, it was required to have matching versions of OVN and OVS. However, if we are releasing OVN more frequently than OVS, the version numbers will end up skewing, potentially resulting in confusion. Thus, we may change the versioning scheme of OVN altogether. I have started a &lt;a href="https://mail.openvswitch.org/pipermail/ovs-dev/2019-August/361439.html"&gt;mailing list discussion&lt;/a&gt; with a document that proposes a shorter release cycle and a new version numbering scheme.&lt;/p&gt; &lt;p&gt;Many smaller cleanup tasks also need to be done. For instance, the Documentation folder still contains many references to &amp;#8220;Open vSwitch&amp;#8221; instead of &amp;#8220;OVN.&amp;#8221; OVS had some supplementary material for convenience. For example, it contained files for building quick vagrant environments. OVN could benefit from similar amenities.&lt;/p&gt; &lt;p&gt;Other administrative tasks are being worked on. For instance, work is being done to create separate mailing lists for OVN so that the multitude of OVN discussions don&amp;#8217;t &amp;#8220;pollute&amp;#8221; the OVS lists. There are also efforts to create a separate ovn.org website, which is separate from the openvswitch.org website.&lt;/p&gt; &lt;p&gt;OVN continues to grow and be a leading solution for creating virtual networks. The separation of OVN from OVS marks a milestone nearly five years in the making. With OVN separated from OVS, this is a great jumping-off point for greater new features, and a fantastic time to join in the development of the project if you are interested.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F08%2F30%2Fthe-clean-break-of-open-virtual-network-from-open-vswitch%2F&amp;#38;linkname=The%20clean%20break%20of%20Open%20Virtual%20Network%20from%20Open%20vSwitch" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F08%2F30%2Fthe-clean-break-of-open-virtual-network-from-open-vswitch%2F&amp;#38;linkname=The%20clean%20break%20of%20Open%20Virtual%20Network%20from%20Open%20vSwitch" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F08%2F30%2Fthe-clean-break-of-open-virtual-network-from-open-vswitch%2F&amp;#38;linkname=The%20clean%20break%20of%20Open%20Virtual%20Network%20from%20Open%20vSwitch" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F08%2F30%2Fthe-clean-break-of-open-virtual-network-from-open-vswitch%2F&amp;#38;linkname=The%20clean%20break%20of%20Open%20Virtual%20Network%20from%20Open%20vSwitch" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F08%2F30%2Fthe-clean-break-of-open-virtual-network-from-open-vswitch%2F&amp;#38;linkname=The%20clean%20break%20of%20Open%20Virtual%20Network%20from%20Open%20vSwitch" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F08%2F30%2Fthe-clean-break-of-open-virtual-network-from-open-vswitch%2F&amp;#38;linkname=The%20clean%20break%20of%20Open%20Virtual%20Network%20from%20Open%20vSwitch" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F08%2F30%2Fthe-clean-break-of-open-virtual-network-from-open-vswitch%2F&amp;#38;linkname=The%20clean%20break%20of%20Open%20Virtual%20Network%20from%20Open%20vSwitch" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F08%2F30%2Fthe-clean-break-of-open-virtual-network-from-open-vswitch%2F&amp;#038;title=The%20clean%20break%20of%20Open%20Virtual%20Network%20from%20Open%20vSwitch" data-a2a-url="https://developers.redhat.com/blog/2019/08/30/the-clean-break-of-open-virtual-network-from-open-vswitch/" data-a2a-title="The clean break of Open Virtual Network from Open vSwitch"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/08/30/the-clean-break-of-open-virtual-network-from-open-vswitch/"&gt;The clean break of Open Virtual Network from Open vSwitch&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/EH196gny7bs" height="1" width="1" alt=""/&gt;</content><summary>After loads of email and IRC discussions, the Open Virtual Network (OVN) source code has been separated from the Open vSwitch (OVS) source code, and the two projects now operate independently. In this article, we’ll explain the reasons for separating OVN from OVS, the technical aspects of the split, and the upcoming challenges for the OVN project. Background OVN was initially announced on the OVS ...</summary><dc:creator>Mark Michelson</dc:creator><dc:date>2019-08-30T07:01:21Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/08/30/the-clean-break-of-open-virtual-network-from-open-vswitch/</feedburner:origLink></entry><entry><title>Easily deploy Node.js applications to Red Hat OpenShift using Nodeshift</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/YixFhEqvcfk/" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="javascript" scheme="searchisko:content:tags" /><category term="Node.js" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift Application Runtimes" scheme="searchisko:content:tags" /><author><name>Lucas Holmquist</name></author><id>searchisko:content:id:jbossorg_blog-easily_deploy_node_js_applications_to_red_hat_openshift_using_nodeshift</id><updated>2019-08-30T07:00:18Z</updated><published>2019-08-30T07:00:18Z</published><content type="html">&lt;p&gt;I recently wrote articles on &lt;a href="https://developers.redhat.com/blog/2018/04/16/zero-express-openshift-3-commands/"&gt;deploying an Express.js application to OpenShift&lt;/a&gt;, &lt;a href="https://developers.redhat.com/blog/2018/05/15/debug-your-node-js-application-on-openshift-with-chrome-devtools/" target="_blank" rel="noopener noreferrer"&gt;how to debug your Node.js application on OpenShift with Chrome Dev Tools&lt;/a&gt; and a short series on &lt;a href="https://developers.redhat.com/blog/2018/10/04/modern-web-apps-openshift-part-1/"&gt;deploying modern web applications to OpenShift&lt;/a&gt;. All of those articles used a node module called &lt;a href="https://www.npmjs.com/package/nodeshift" target="_blank" rel="noopener noreferrer"&gt;Nodeshift&lt;/a&gt;, but I did a Jedi, hand-wavy thing when talking about it. This next series of articles takes a deeper look at what Nodeshift is and how it is used to ease the deployment of Node.js apps to OpenShift during development.&lt;span id="more-491407"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Basic app deployment on Red Hat OpenShift&lt;/h2&gt; &lt;p&gt;Although there are different approaches to how one deploys an application to &lt;a href="https://developers.redhat.com/openshift/"&gt;Red Hat OpenShift&lt;/a&gt;, we will look at the workflow I like to use. This specific workflow uses Source-to-Image (S2I) images and source code that is located on my local machine. Before we take a look at Nodeshift, though, let&amp;#8217;s first take a quick look at some of the parts that this workflow uses. This flow can logically be broken into two parts: the &lt;strong&gt;Build Phase&lt;/strong&gt; and the &lt;strong&gt;Deploy Phase&lt;/strong&gt;.&lt;/p&gt; &lt;h3&gt;Part 1: The Build Phase&lt;/h3&gt; &lt;p&gt;The first phase of this workflow is all about building an image to eventually run in the Deploy phase. For our Node.js app, this is the phase where we install our dependencies and run any build scripts. If you are familiar with the phases of S2I, this phase is where the assemble script runs.&lt;/p&gt; &lt;p&gt;Using a BuildConfig, we can specify where our code comes from and what type of strategy to use when building the code. In our case, we use the DockerImage strategy since we are using a Node.js S2I image. The BuildConfig also tells OpenShift where to put our built code when it is done: In our case, an ImageStream.&lt;/p&gt; &lt;p&gt;Initially, we create an empty ImageStream, and then we populate that with the results of a successful build. In fact, if you were to look at OpenShift&amp;#8217;s internal image registry you would see that image there, similar to how you would see a container image on your local machine when running something like &lt;code&gt;docker images&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;Part 2: The Deploy Phase&lt;/h3&gt; &lt;p&gt;The second phase of this workflow is all about running our application and setting it up to be accessed. For our Node.js app, this is the phase where we might run something like &lt;code&gt;npm run start&lt;/code&gt; to launch our application. Again, if you are familiar with the phases of S2I, this phase is where the run script runs. By default, the Node.js S2I image that we use here this same command: &lt;code&gt;npm run start&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Using a DeploymentConfig, we can then trigger the S2I run phase. DeploymentConfigs are also used to describe our application (what ImageStream to use, any environment variables, setting up health checks, and so on). Once a Deployment is successful, a running Pod is created.&lt;/p&gt; &lt;p&gt;Next, we need a Service for the new Pod&amp;#8217;s internal load balancing, as well as a Route if we want to access our application outside of the OpenShift context.&lt;/p&gt; &lt;p&gt;While this workflow is not too complicated, there are many different pieces that work together. Those pieces are also YAML files, which at times can be difficult to read and interpret.&lt;/p&gt; &lt;h2&gt;Nodeshift basics&lt;/h2&gt; &lt;p&gt;Now that we have a little background on deploying applications to OpenShift, let&amp;#8217;s talk about Nodeshift and what it is. According to the Nodeshift module readme:&lt;/p&gt; &lt;blockquote&gt;&lt;p&gt;Nodeshift is an opinionated command-line application and programmable API that you can use to deploy Node.js projects to OpenShift.&lt;/p&gt;&lt;/blockquote&gt; &lt;p&gt;The opinion that Nodeshift takes is the workflow that I&amp;#8217;ve just described, which allows the user to develop their application and deploy it to OpenShift, without having to think about all those different YAML files.&lt;/p&gt; &lt;p&gt;Nodeshift is also written in Node.js, so it can fit into a Node developer&amp;#8217;s current workflow or be added to an existing project using &lt;code&gt;npm install&lt;/code&gt;. The only real prerequisite is that you are logged into your OpenShift cluster using &lt;code&gt;oc login&lt;/code&gt;, but that isn&amp;#8217;t really a requirement. You can also specify an external config file, which we will see in a later article about more advanced usage.&lt;/p&gt; &lt;h3&gt;Running Nodeshift&lt;/h3&gt; &lt;p&gt;Using Nodeshift on the command line is easy. You can install it globally:&lt;/p&gt; &lt;pre&gt;$ npm install -g nodeshift $ nodeshift --help &lt;/pre&gt; &lt;p&gt;or by using &lt;code&gt;&lt;a href="https://www.npmjs.com/package/npx"&gt;npx&lt;/a&gt;&lt;/code&gt;, which is the preferred way:&lt;/p&gt; &lt;pre&gt;$ npx nodeshift --help &lt;/pre&gt; &lt;p&gt;As is the case with every other command-line tool, running Nodeshift with that &lt;code&gt;--help&lt;/code&gt; flag shows us the commands and flags that are available to use:&lt;/p&gt; &lt;pre&gt;Commands: nodeshift deploy default command - deploy [default] nodeshift build build command nodeshift resource resource command nodeshift apply-resource apply resource command nodeshift undeploy [removeAll] undeploy resources Options: --help Show help [boolean] --version Show version number [boolean] --projectLocation change the default location of the project [string] --configLocation change the default location of the config [string] --dockerImage the s2i image to use, defaults to nodeshift/centos7-s2i-nodejs [string] --imageTag The tag of the docker image to use for the deployed application. [string] [default: "latest"] --outputImageStream The name of the ImageStream to output to. Defaults to project name from package.json [string] --outputImageStreamTag The tag of the ImageStream to output to. [string] --quiet supress INFO and TRACE lines from output logs [boolean] --expose flag to create a default Route and expose the default service [boolean] [choices: true, false] [default: false] --namespace.displayName flag to specify the project namespace display name to build/deploy into. Overwrites any namespace settings in your OpenShift or Kubernetes configuration files [string] --namespace.create flag to create the namespace if it does not exist. Only applicable for the build and deploy command. Must be used with namespace.name [boolean] --namespace.remove flag to remove the user created namespace. Only applicable for the undeploy command. Must be used with namespace.name [boolean] --namespace.name flag to specify the project namespace name to build/deploy into. Overwrites any namespace settings in your OpenShift or Kubernetes configuration files [string] --deploy.port flag to update the default ports on the resource files. Defaults to 8080 [default: 8080] --build.recreate flag to recreate a buildConfig or Imagestream [choices: "buildConfig", "imageStream", false, true] [default: false] --build.forcePull flag to make your BuildConfig always pull a new image from dockerhub or not [boolean] [choices: true, false] [default: false] --build.incremental flag to perform incremental builds, which means it reuses artifacts from previously-built images [boolean] [choices: true, false] [default: false] --metadata.out determines what should be done with the response metadata from OpenShift [string] [choices: "stdout", "ignore", ""] [default: "ignore"] --cmd [default: "deploy"] &lt;/pre&gt; &lt;p&gt;Let&amp;#8217;s take a look at the most common usage.&lt;/p&gt; &lt;h3&gt;Deploying Nodeshift&lt;/h3&gt; &lt;p&gt;Let&amp;#8217;s say we have a simple express.js application that we have been working on locally, which we&amp;#8217;ve bound to port 8080, and we want to deploy this application to OpenShift. We just run:&lt;/p&gt; &lt;pre&gt; $ npx nodeshift &lt;/pre&gt; &lt;p&gt;Once that command runs, Nodeshift goes to work. Here are the steps that the command goes through using the default deploy command:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Nodeshift packages your source code into a &lt;code&gt;tar&lt;/code&gt; file to upload to the OpenShift cluster.&lt;/li&gt; &lt;li&gt;Nodeshift looks at the &lt;code&gt;files&lt;/code&gt; property of your application&amp;#8217;s &lt;code&gt;package.json&lt;/code&gt; (by default, it ignores any &lt;code&gt;node_modules&lt;/code&gt;, &lt;code&gt;tmp&lt;/code&gt;, or &lt;code&gt;.git&lt;/code&gt; folders): &lt;ul&gt; &lt;li&gt;If a &lt;code&gt;files&lt;/code&gt; property exists, Nodeshift uses &lt;code&gt;tar&lt;/code&gt; to archive those files.&lt;/li&gt; &lt;li&gt;If there is no &lt;code&gt;files&lt;/code&gt; property, Nodeshift archives the current directory.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Once the archive is created, a new BuildConfig and ImageStream are created on the remote cluster.&lt;/li&gt; &lt;li&gt;The archive is uploaded.&lt;/li&gt; &lt;li&gt;An OpenShift Build starts running on OpenShift.&lt;/li&gt; &lt;li&gt;Nodeshift watches that build process and outputs the remote log to the console.&lt;/li&gt; &lt;li&gt;Once the build is completed, Nodeshift then creates a DeploymentConfig, which triggers an actual deployment, and also a Kubernetes Service. (A Route is not created by default, but if one is desired, you can use the &lt;code&gt;--expose&lt;/code&gt; flag.)&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;If you make code changes and run the &lt;code&gt;nodeshift&lt;/code&gt; command again, the process happens again, but this time it uses the existing config files that were created on the first run.&lt;/p&gt; &lt;h2&gt;Until next time&lt;/h2&gt; &lt;p&gt;In this article, we looked at the anatomy of a Red Hat OpenShift deployment and how Nodeshift can help abstract the complexity with a simple example. Stay tuned for future articles, in which we will look at other commands that Nodeshift provides. In those articles, we will explore several commonly used options and show how to use Nodeshift in our code instead of just using it at the command line.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F08%2F30%2Feasily-deploy-node-js-applications-to-red-hat-openshift-using-nodeshift%2F&amp;#38;linkname=Easily%20deploy%20Node.js%20applications%20to%20Red%20Hat%20OpenShift%20using%20Nodeshift" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F08%2F30%2Feasily-deploy-node-js-applications-to-red-hat-openshift-using-nodeshift%2F&amp;#38;linkname=Easily%20deploy%20Node.js%20applications%20to%20Red%20Hat%20OpenShift%20using%20Nodeshift" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F08%2F30%2Feasily-deploy-node-js-applications-to-red-hat-openshift-using-nodeshift%2F&amp;#38;linkname=Easily%20deploy%20Node.js%20applications%20to%20Red%20Hat%20OpenShift%20using%20Nodeshift" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F08%2F30%2Feasily-deploy-node-js-applications-to-red-hat-openshift-using-nodeshift%2F&amp;#38;linkname=Easily%20deploy%20Node.js%20applications%20to%20Red%20Hat%20OpenShift%20using%20Nodeshift" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F08%2F30%2Feasily-deploy-node-js-applications-to-red-hat-openshift-using-nodeshift%2F&amp;#38;linkname=Easily%20deploy%20Node.js%20applications%20to%20Red%20Hat%20OpenShift%20using%20Nodeshift" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F08%2F30%2Feasily-deploy-node-js-applications-to-red-hat-openshift-using-nodeshift%2F&amp;#38;linkname=Easily%20deploy%20Node.js%20applications%20to%20Red%20Hat%20OpenShift%20using%20Nodeshift" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F08%2F30%2Feasily-deploy-node-js-applications-to-red-hat-openshift-using-nodeshift%2F&amp;#38;linkname=Easily%20deploy%20Node.js%20applications%20to%20Red%20Hat%20OpenShift%20using%20Nodeshift" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F08%2F30%2Feasily-deploy-node-js-applications-to-red-hat-openshift-using-nodeshift%2F&amp;#038;title=Easily%20deploy%20Node.js%20applications%20to%20Red%20Hat%20OpenShift%20using%20Nodeshift" data-a2a-url="https://developers.redhat.com/blog/2019/08/30/easily-deploy-node-js-applications-to-red-hat-openshift-using-nodeshift/" data-a2a-title="Easily deploy Node.js applications to Red Hat OpenShift using Nodeshift"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/08/30/easily-deploy-node-js-applications-to-red-hat-openshift-using-nodeshift/"&gt;Easily deploy Node.js applications to Red Hat OpenShift using Nodeshift&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/YixFhEqvcfk" height="1" width="1" alt=""/&gt;</content><summary>I recently wrote articles on deploying an Express.js application to OpenShift, how to debug your Node.js application on OpenShift with Chrome Dev Tools and a short series on deploying modern web applications to OpenShift. All of those articles used a node module called Nodeshift, but I did a Jedi, hand-wavy thing when talking about it. This next series of articles takes a deeper look at what Nodes...</summary><dc:creator>Lucas Holmquist</dc:creator><dc:date>2019-08-30T07:00:18Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/08/30/easily-deploy-node-js-applications-to-red-hat-openshift-using-nodeshift/</feedburner:origLink></entry><entry><title>Extending support for Spring Boot 2.1.6 and Spring Reactive</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/6bNrZtVxqkQ/" /><category term="Announcement" scheme="searchisko:content:tags" /><category term="Eclipse Vert.x" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Java" scheme="searchisko:content:tags" /><category term="Modern App Dev" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift Application Runtimes" scheme="searchisko:content:tags" /><category term="Spring Boot" scheme="searchisko:content:tags" /><author><name>James Falkner</name></author><id>searchisko:content:id:jbossorg_blog-extending_support_for_spring_boot_2_1_6_and_spring_reactive</id><updated>2019-08-30T07:00:05Z</updated><published>2019-08-30T07:00:05Z</published><content type="html">&lt;div style="float: right;"&gt;&lt;/div&gt; &lt;p&gt;&lt;a href="https://www.redhat.com/en/products/application-runtimes" target="_blank" rel="noopener noreferrer"&gt;Red Hat Application Runtimes&lt;/a&gt; recently added extended support for the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_application_runtimes/1/html/spring_boot_2.1.x_runtime_guide/index" target="_blank" rel="noopener noreferrer"&gt;Spring Boot 2.1.6 runtime&lt;/a&gt; for Red Hat customers building Spring apps. Red Hat Application Runtimes provides application developers with a variety of application runtimes running on the &lt;a href="https://developers.redhat.com/openshift/"&gt;Red Hat OpenShift Container Platform&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Introduction to Spring Boot&lt;/h2&gt; &lt;p&gt;&lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_application_runtimes/1/html/spring_boot_tomcat_runtime_guide/" target="_blank" rel="noopener noreferrer"&gt;Spring Boot&lt;/a&gt; lets you create opinionated Spring-based standalone applications. The Spring Boot runtime also integrates with the OpenShift platform, allowing your services to externalize their configuration, implement health checks, provide resiliency and failover, and much more.&lt;/p&gt; &lt;p&gt;&lt;span id="more-619937"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;What&amp;#8217;s new?&lt;/h2&gt; &lt;p&gt;This release introduces extended support for Spring Boot 2.1.6, and two &lt;a href="https://access.redhat.com/support/offerings/techpreview/" target="_blank" rel="noopener noreferrer"&gt;technology preview&lt;/a&gt; features:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://github.com/dekorateio/dekorate"&gt;Dekorate&lt;/a&gt;, a Java annotation processor for Kubernetes, formerly developed under the name AP4K. Dekorate is a tool for automatically updating Kubernetes and OpenShift configuration files without the need to manually edit individual XML, YAML, or JSON templates. When declared as a dependency in your Maven project, Dekorate automatically picks up annotations and changes them to properties that you set in your application, automatically updating the corresponding deployment configuration and resource definition templates.&lt;/li&gt; &lt;li&gt;Vert.X Reactive Components, a set of supported starters for designing reactive applications. The productized starters are based on the community releases &lt;a href="https://docs.spring.io/spring/docs/current/spring-framework-reference/web-reactive.html#webflux" target="_blank" rel="noopener noreferrer"&gt;Spring WebFlux&lt;/a&gt; and &lt;a href="https://projectreactor.io/docs/netty/release/reference/index.html" target="_blank" rel="noopener noreferrer"&gt;Reactor Netty&lt;/a&gt;, with a set of additional &lt;a href="https://vertx.io" target="_blank" rel="noopener noreferrer"&gt;Eclipse Vert.x&lt;/a&gt; extensions for the Spring Boot runtimes that extend the reactive capabilities of Spring WebFlux to include an asynchronous I/O API that handles network communication between individual application components. This addition lets you create a fully Red Hat-supported reactive stack that you can use to build your Spring Boot applications.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Consult the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_application_runtimes/1/html/red_hat_openshift_application_runtimes_release_notes/" target="_blank" rel="noopener noreferrer"&gt;release notes&lt;/a&gt; for a complete list of what&amp;#8217;s new.&lt;/p&gt; &lt;h2&gt;Get started&lt;/h2&gt; &lt;div id="attachment_619967" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="http://developers.redhat.com/launch"&gt;&lt;img aria-describedby="caption-attachment-619967" class="wp-image-619967 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/08/Screen-Shot-2019-08-14-at-3.50.38-PM-1024x495.png" alt="" width="640" height="309" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/08/Screen-Shot-2019-08-14-at-3.50.38-PM-1024x495.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/08/Screen-Shot-2019-08-14-at-3.50.38-PM-300x145.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/08/Screen-Shot-2019-08-14-at-3.50.38-PM-768x371.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/08/Screen-Shot-2019-08-14-at-3.50.38-PM.png 1187w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-619967" class="wp-caption-text"&gt;Launcher in action.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Using &lt;a href="https://developers.redhat.com/launch"&gt;developers.redhat.com/launch&lt;/a&gt;, you can immediately create and deploy a Spring Boot application directly to &lt;a href="http://openshift.com/" target="_blank" rel="noopener noreferrer"&gt;OpenShift Online&lt;/a&gt; or to your own local OpenShift cluster. This tool provides a hassle-free way of creating applications from scratch, starting with example applications or importing your own, as well as an easy way to build and deploy those applications to Red Hat OpenShift.&lt;/p&gt; &lt;p&gt;Examples are available to showcase how developers can use Spring Boot to build the fundamental building blocks of cloud-native applications and services, such as creating secured RESTful APIs, implementing health checks, externalizing configuration, securing resources, or integrating with the OpenShift Service Mesh based on the &lt;a href="https://developers.redhat.com/topics/service-mesh/"&gt;Istio&lt;/a&gt; project.&lt;/p&gt; &lt;h2&gt;Using Dekorate&lt;/h2&gt; &lt;p&gt;To start using &lt;a href="http://dekorate.io/" target="_blank" rel="noopener noreferrer"&gt;Dekorate&lt;/a&gt; you just need to add one dependency to your &lt;code&gt;pom.xml&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;&amp;#60;dependency&amp;#62; &amp;#60;groupId&amp;#62;io.dekorate&amp;#60;/groupId&amp;#62; &amp;#60;artifactId&amp;#62;kubernetes-annotations&amp;#60;/artifactId&amp;#62; &amp;#60;version&amp;#62;${project.version}&amp;#60;/version&amp;#62; &amp;#60;/dependency&amp;#62; &lt;/pre&gt; &lt;p&gt;Then, add one of the provided annotations to your project. For example:&lt;/p&gt; &lt;pre&gt;import io.dekorate.kubernetes.annotaion.KubernetesApplication; @KubernetesApplication public class Main { public static void main(String[] args) { //Your application code goes here. } } &lt;/pre&gt; &lt;p&gt;When this project gets compiled, the annotation will trigger the generation of a &lt;em&gt;Deployment&lt;/em&gt; in both JSON and YAML that will end up under the &lt;code&gt;target/classes/META-INF/dekorate&lt;/code&gt; directory. This Deployment can then be &lt;em&gt;applied&lt;/em&gt; to your Kubernetes cluster with &lt;code&gt;kubectl apply -f target/classes/META-INF/dekorate/kubernetes.yml&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;The annotation comes with a lot of optional parameters, which can be used to customize the Deployment and trigger the generation of additional resources, like &lt;em&gt;Service&lt;/em&gt; and &lt;em&gt;Ingress&lt;/em&gt;. Other features that you can add to your application for various services include:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="http://developers.redhat.com/openshift/" rel="noopener noreferrer"&gt;OpenShift&lt;/a&gt; to create image streams and build configurations, plus bind to service catalog services.&lt;/li&gt; &lt;li&gt;&lt;a href="http://developers.redhat.com/topics/kubernetes/" rel="noopener noreferrer"&gt;Kubernetes&lt;/a&gt; to add labels, annotations, environment variables, volume mounts, ports/services, JVM options, init containers, and inject sidecars.&lt;/li&gt; &lt;li&gt;&lt;a href="https://prometheus.io" target="_blank" rel="noopener noreferrer"&gt;Prometheus&lt;/a&gt; to configure monitoring.&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.jaegertracing.io/" target="_blank" rel="noopener noreferrer"&gt;Jaeger&lt;/a&gt; to connect your app to distributed tracing.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;For an excellent overview of more Dekorate functionality, check out Gytis &amp;#8216; blog &lt;a href="https://developers.redhat.com/blog/2019/08/15/how-to-use-dekorate-to-create-kubernetes-manifests/"&gt;How to use Dekorate to create Kubernetes manifests&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Building reactive applications with Spring Boot and Eclipse Vert.x&lt;/h2&gt; &lt;p&gt;The Spring reactive stack is built on &lt;a href="https://projectreactor.io/" target="_blank" rel="noopener noreferrer"&gt;Project Reactor&lt;/a&gt;, a reactive library that implements backpressure and is compliant with the Reactive Streams specification. It provides the &lt;a href="https://projectreactor.io/docs/core/release/api/reactor/core/publisher/Flux.html" target="_blank" rel="noopener noreferrer"&gt;Flux&lt;/a&gt; and &lt;a href="https://projectreactor.io/docs/core/release/api/reactor/core/publisher/Mono.html" target="_blank" rel="noopener noreferrer"&gt;Mono&lt;/a&gt; functional API types that enable asynchronous event stream processing. On top of Project Reactor, Spring provides &lt;a href="https://docs.spring.io/spring/docs/current/spring-framework-reference/web-reactive.html#webflux" target="_blank" rel="noopener noreferrer"&gt;WebFlux&lt;/a&gt;, an asynchronous event-driven web application framework. Reactive applications built with this stack enable non-blocking, asynchronous, event-driven apps that are highly scalable and resilient. They also ease integration with other related reactive libraries like &lt;a href="https://activemq.apache.org/components/artemis/" target="_blank" rel="noopener noreferrer"&gt;Apache ActiveMQ Artemis&lt;/a&gt;, &lt;a href="https://kafka.apache.org/" target="_blank" rel="noopener noreferrer"&gt;Apache Kafka&lt;/a&gt;, or &lt;a href="https://infinispan.org/" target="_blank" rel="noopener noreferrer"&gt;Infinispan&lt;/a&gt; (all fully supported via &lt;a href="https://www.redhat.com/en/products/middleware" target="_blank" rel="noopener noreferrer"&gt;Red Hat Middleware&lt;/a&gt;).&lt;/p&gt; &lt;p&gt;This Spring reactive offering by Red Hat brings the benefits of Reactor and WebFlux to OpenShift and standalone Red Hat Enterprise Linux, and it introduces a set of &lt;a href="https://vertx.io" target="_blank" rel="noopener noreferrer"&gt;Eclipse Vert.x&lt;/a&gt; extensions for the WebFlux framework. This addition allows you to retain the level of abstraction and rapid prototyping capabilities of Spring Boot, and provides an asynchronous I/O API that handles the network communications between the services in your application in a fully reactive manner.&lt;/p&gt; &lt;p&gt;To create a basic reactive HTTP web service, add the following dependency to your &lt;code&gt;pom.xml&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;&amp;#60;dependency&amp;#62; &amp;#60;groupId&amp;#62;dev.snowdrop&amp;#60;/groupId&amp;#62; &amp;#60;artifactId&amp;#62;vertx-spring-boot-starter-http&amp;#60;/artifactId&amp;#62; &amp;#60;/dependency&amp;#62; &lt;/pre&gt; &lt;p&gt;This addition brings in the required dependencies to create reactive applications. Next, create a reactive sample app:&lt;/p&gt; &lt;pre&gt;package dev.snowdrop.vertx.sample.http; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; import org.springframework.context.annotation.Bean; import org.springframework.web.reactive.function.server.RouterFunction; import org.springframework.web.reactive.function.server.ServerRequest; import org.springframework.web.reactive.function.server.ServerResponse; import reactor.core.publisher.Mono; import static org.springframework.web.reactive.function.BodyInserters.fromObject; import static org.springframework.web.reactive.function.server.RouterFunctions.route; import static org.springframework.web.reactive.function.server.ServerResponse.ok; @SpringBootApplication public class HttpSampleApplication { public static void main(String[] args) { SpringApplication.run(HttpSampleApplication.class, args); } @Bean public RouterFunction&amp;#60;ServerResponse&amp;#62; helloRouter() { return route() .GET("/hello", this::helloHandler) .build(); } private Mono&amp;#60;ServerResponse&amp;#62; helloHandler(ServerRequest request) { String name = request .queryParam("name") .orElse("World"); String message = String.format("Hello, %s!", name); return ok() .body(fromObject(message)); } } &lt;/pre&gt; &lt;p&gt;Finally, build and test:&lt;/p&gt; &lt;pre&gt;$ mvn clean package $ java -jar target/vertx-spring-boot-sample-http.jar $ curl localhost:8080/hello Hello, World! &lt;/pre&gt; &lt;p&gt;There are several other example applications for authentication via OAuth2, reactive email clients, server-sent events, and more in the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_application_runtimes/1/html/spring_boot_2.1.x_runtime_guide/developing-reactive-applications-using-spring-boot-vertx_spring-boot" target="_blank" rel="noopener noreferrer"&gt;Spring Boot Runtime Guide&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;For more detail on creating reactive web services with Spring Boot, see the &lt;a href="https://spring.io/guides/gs/reactive-rest-service/" target="_blank" rel="noopener noreferrer"&gt;reactive REST service development guide&lt;/a&gt; in the Spring community documentation.&lt;/p&gt; &lt;h2&gt;Documentation&lt;/h2&gt; &lt;p&gt;The Runtimes team has been continuously adding and improving on the official documentation for building apps with Spring Boot. This effort includes updates in the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_application_runtimes/1/html/rhoar_spring_boot_2.1.x_release_notes/" target="_blank" rel="noopener noreferrer"&gt;Release Notes&lt;/a&gt;, &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_application_runtimes/1/html/getting_started_with_red_hat_openshift_application_runtimes/" target="_blank" rel="noopener noreferrer"&gt;Getting Started Guide,&lt;/a&gt; and the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_application_runtimes/1/html/spring_boot_2.1.x_runtime_guide/" target="_blank" rel="noopener noreferrer"&gt;Spring Boot Runtime Guide&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Developer interactive learning scenarios&lt;/h2&gt; &lt;p&gt;These &lt;a href="https://learn.openshift.com/middleware/rhoar-getting-started-thorntail/" target="_blank" rel="noopener noreferrer"&gt;self-paced scenarios&lt;/a&gt; provide you with a preconfigured Red Hat OpenShift instance, accessible from your browser without any downloads or configuration. Use it to experiment with Spring Boot or learn about other technologies within Red Hat Application Runtimes and see how it helps solve real-world problems:&lt;/p&gt; &lt;div id="attachment_619977" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://learn.openshift.com/middleware/courses/middleware-spring-boot/"&gt;&lt;img aria-describedby="caption-attachment-619977" class="wp-image-619977 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/08/Screen-Shot-2019-08-14-at-3.54.45-PM-1024x631.png" alt="" width="640" height="394" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/08/Screen-Shot-2019-08-14-at-3.54.45-PM-1024x631.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/08/Screen-Shot-2019-08-14-at-3.54.45-PM-300x185.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/08/Screen-Shot-2019-08-14-at-3.54.45-PM-768x474.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/08/Screen-Shot-2019-08-14-at-3.54.45-PM.png 1093w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-619977" class="wp-caption-text"&gt;Available self-paced learning guides.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Getting support for Spring Boot&lt;/h2&gt; &lt;p&gt;Support for Spring Boot is available to Red Hat customers through a subscription to &lt;a href="https://developers.redhat.com/products/rhoar/overview/"&gt;Red Hat OpenShift Application Runtimes&lt;/a&gt;. Contact your local Red Hat representative or &lt;a href="https://www.redhat.com/en/about/contact/sales" target="_blank" rel="noopener noreferrer"&gt;Red Hat Sales&lt;/a&gt; for details on how you can enjoy the world-class support offered by Red Hat and its worldwide partner network. More information on what&amp;#8217;s included can be found in &lt;a href="https://developers.redhat.com/blog/2019/02/28/spring-boot-2-x-red-hat-openshift-application-runtimes-rhoar/"&gt;Extending support to Spring Boot 2.x for Red Hat OpenShift Application Runtimes&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Moving forward, customers can expect support for Spring Boot and other runtimes according to the &lt;a href="https://access.redhat.com/support/policy/updates/jboss_notes/" target="_blank" rel="noopener noreferrer"&gt;Red Hat Product Update and Support Lifecycle&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;What’s next for Spring Boot support?&lt;/h3&gt; &lt;p&gt;The Runtimes Spring Boot team is continually taking &lt;a href="https://issues.jboss.org/projects/SB" target="_blank" rel="noopener noreferrer"&gt;feedback&lt;/a&gt; from customers and the wider community of open source developers, as well as tracking the &lt;a href="https://github.com/spring-projects/spring-boot/releases" target="_blank" rel="noopener noreferrer"&gt;upstream Spring Boot releases&lt;/a&gt;. The team is working to make updates to support based on that feedback, as well as considering support for additional modules from Red Hat and the large Java and Spring community.&lt;/p&gt; &lt;h3&gt;The people behind Red Hat&amp;#8217;s Spring Boot support&lt;/h3&gt; &lt;p&gt;This offering was produced by Red Hat’s Application Runtimes product and engineering team along with the &lt;a href="https://snowdrop.me" target="_blank" rel="noopener noreferrer"&gt;Snowdrop&lt;/a&gt; upstream community, and involved many hours of development, testing, documentation writing, testing some more, and working with the wider Red Hat community of customers, partners, and Spring developers to incorporate contributions, both big and small. We are glad you have chosen to use it and hope that it meets or exceeds your expectations!&lt;/p&gt; &lt;h3&gt;Spring Boot resources&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/products/rhoar/overview/"&gt;Red Hat OpenShift Application Runtimes Developer home page&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_application_runtimes/1/html/spring_boot_runtime_guide/" target="_blank" rel="noopener noreferrer"&gt;Spring Boot Runtime Guide&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://issues.jboss.org/projects/SB" target="_blank" rel="noopener noreferrer"&gt;Spring Boot Issue Tracker&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://learn.openshift.com/middleware/courses/middleware-spring-boot/" target="_blank" rel="noopener noreferrer"&gt;Interactive Learning Scenarios for Spring Boot on OpenShift&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://snowdrop.me/" target="_blank" rel="noopener noreferrer"&gt;Snowdrop upstream project&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F08%2F30%2Fextending-support-for-spring-boot-2-1-6-and-spring-reactive%2F&amp;#38;linkname=Extending%20support%20for%20Spring%20Boot%202.1.6%20and%20Spring%20Reactive" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F08%2F30%2Fextending-support-for-spring-boot-2-1-6-and-spring-reactive%2F&amp;#38;linkname=Extending%20support%20for%20Spring%20Boot%202.1.6%20and%20Spring%20Reactive" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F08%2F30%2Fextending-support-for-spring-boot-2-1-6-and-spring-reactive%2F&amp;#38;linkname=Extending%20support%20for%20Spring%20Boot%202.1.6%20and%20Spring%20Reactive" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F08%2F30%2Fextending-support-for-spring-boot-2-1-6-and-spring-reactive%2F&amp;#38;linkname=Extending%20support%20for%20Spring%20Boot%202.1.6%20and%20Spring%20Reactive" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F08%2F30%2Fextending-support-for-spring-boot-2-1-6-and-spring-reactive%2F&amp;#38;linkname=Extending%20support%20for%20Spring%20Boot%202.1.6%20and%20Spring%20Reactive" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F08%2F30%2Fextending-support-for-spring-boot-2-1-6-and-spring-reactive%2F&amp;#38;linkname=Extending%20support%20for%20Spring%20Boot%202.1.6%20and%20Spring%20Reactive" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F08%2F30%2Fextending-support-for-spring-boot-2-1-6-and-spring-reactive%2F&amp;#38;linkname=Extending%20support%20for%20Spring%20Boot%202.1.6%20and%20Spring%20Reactive" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F08%2F30%2Fextending-support-for-spring-boot-2-1-6-and-spring-reactive%2F&amp;#038;title=Extending%20support%20for%20Spring%20Boot%202.1.6%20and%20Spring%20Reactive" data-a2a-url="https://developers.redhat.com/blog/2019/08/30/extending-support-for-spring-boot-2-1-6-and-spring-reactive/" data-a2a-title="Extending support for Spring Boot 2.1.6 and Spring Reactive"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/08/30/extending-support-for-spring-boot-2-1-6-and-spring-reactive/"&gt;Extending support for Spring Boot 2.1.6 and Spring Reactive&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/6bNrZtVxqkQ" height="1" width="1" alt=""/&gt;</content><summary>Red Hat Application Runtimes recently added extended support for the Spring Boot 2.1.6 runtime for Red Hat customers building Spring apps. Red Hat Application Runtimes provides application developers with a variety of application runtimes running on the Red Hat OpenShift Container Platform. Introduction to Spring Boot Spring Boot lets you create opinionated Spring-based standalone applications. Th...</summary><dc:creator>James Falkner</dc:creator><dc:date>2019-08-30T07:00:05Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/08/30/extending-support-for-spring-boot-2-1-6-and-spring-reactive/</feedburner:origLink></entry></feed>
